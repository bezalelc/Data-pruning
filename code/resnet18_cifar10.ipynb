{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# in this notebook:\n",
    " run different model for find the best variation for resnet18 on cifar10\n",
    "    - learning rade\n",
    "    - scheduler for learning rate\n",
    "    - optimizer (Adam or SGD)\n",
    "    - last fully connected layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from train import ModelManager\n",
    "from utils import get_loader, get_cifar10\n",
    "\n",
    "# globals\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 25\n",
    "NUM_TRAIN = 50000\n",
    "NUM_TEST = 10000\n",
    "EPOCHS = 60\n",
    "\n",
    "NOTEBOOK_NAME = 'resnet18_cifar10'\n",
    "\n",
    "print('train on:', ModelManager.DEVICE)\n",
    "\n",
    "train_idx = np.arange(NUM_TRAIN, dtype=int)\n",
    "test_idx = np.arange(NUM_TEST, dtype=int)\n",
    "dataset_train, dataset_test, dataset_train_for_test, dataset_train_raw = get_cifar10()\n",
    "loader_train = get_loader(dataset_train, train_idx, BATCH_SIZE, shuffle=True)\n",
    "loader_test = get_loader(dataset_test, test_idx, BATCH_SIZE, shuffle=False)\n",
    "loader_train_ordered = get_loader(dataset_train_for_test, train_idx, BATCH_SIZE, shuffle=False)\n",
    "Y_train = Tensor(dataset_train.targets)[train_idx].type(torch.int64)\n",
    "Y_test = Tensor(dataset_test.targets)[test_idx].type(torch.int64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Epoch: 0 Training: Loss: 0.057800 Acc: 0.474240  Validation Loss: 0.044208 Acc: 0.612200                                                    \n",
      "Validation loss decreased (inf --> 0.044208).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 1 Training: Loss: 0.043911 Acc: 0.611920  Validation Loss: 0.036989 Acc: 0.683400                                                     \n",
      "Validation loss decreased (0.044208 --> 0.036989).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 2 Training: Loss: 0.038353 Acc: 0.664700  Validation Loss: 0.035815 Acc: 0.691400                                                     \n",
      "Validation loss decreased (0.036989 --> 0.035815).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 3 Training: Loss: 0.034343 Acc: 0.702240  Validation Loss: 0.028094 Acc: 0.762300                                                     \n",
      "Validation loss decreased (0.035815 --> 0.028094).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 4 Training: Loss: 0.031186 Acc: 0.730740  Validation Loss: 0.023741 Acc: 0.799000                                                     \n",
      "Validation loss decreased (0.028094 --> 0.023741).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 5 Training: Loss: 0.029043 Acc: 0.751000  Validation Loss: 0.024488 Acc: 0.793100                                                     \n",
      "Epoch: 6 Training: Loss: 0.027045 Acc: 0.767180  Validation Loss: 0.022929 Acc: 0.804700                                                     \n",
      "Validation loss decreased (0.023741 --> 0.022929).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 7 Training: Loss: 0.025488 Acc: 0.779720  Validation Loss: 0.020200 Acc: 0.822800                                                     \n",
      "Validation loss decreased (0.022929 --> 0.020200).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 8 Training: Loss: 0.024500 Acc: 0.790220  Validation Loss: 0.020597 Acc: 0.824300                                                     \n",
      "Epoch: 9 Training: Loss: 0.023193 Acc: 0.799820  Validation Loss: 0.019324 Acc: 0.831400                                                     \n",
      "Validation loss decreased (0.020200 --> 0.019324).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 10 Training: Loss: 0.022287 Acc: 0.807860  Validation Loss: 0.018701 Acc: 0.839600                                                     \n",
      "Validation loss decreased (0.019324 --> 0.018701).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 11 Training: Loss: 0.021146 Acc: 0.818140  Validation Loss: 0.018128 Acc: 0.846200                                                     \n",
      "Validation loss decreased (0.018701 --> 0.018128).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 12 Training: Loss: 0.020786 Acc: 0.823680  Validation Loss: 0.016722 Acc: 0.858400                                                     \n",
      "Validation loss decreased (0.018128 --> 0.016722).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 13 Training: Loss: 0.019766 Acc: 0.830160  Validation Loss: 0.016556 Acc: 0.855100                                                     \n",
      "Validation loss decreased (0.016722 --> 0.016556).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 14 Training: Loss: 0.019210 Acc: 0.836100  Validation Loss: 0.016536 Acc: 0.861900                                                     \n",
      "Validation loss decreased (0.016556 --> 0.016536).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 15 Training: Loss: 0.018440 Acc: 0.841560  Validation Loss: 0.016996 Acc: 0.858100                                                     \n",
      "Epoch: 16 Training: Loss: 0.018176 Acc: 0.843380  Validation Loss: 0.015017 Acc: 0.875700                                                     \n",
      "Validation loss decreased (0.016536 --> 0.015017).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 17 Training: Loss: 0.017554 Acc: 0.847800  Validation Loss: 0.015465 Acc: 0.868900                                                     \n",
      "Epoch: 18 Training: Loss: 0.017074 Acc: 0.852280  Validation Loss: 0.015119 Acc: 0.872200                                                     \n",
      "Epoch: 19 Training: Loss: 0.016367 Acc: 0.858900  Validation Loss: 0.014358 Acc: 0.878600                                                     \n",
      "Validation loss decreased (0.015017 --> 0.014358).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 20 Training: Loss: 0.016180 Acc: 0.860900  Validation Loss: 0.013837 Acc: 0.886400                                                     \n",
      "Validation loss decreased (0.014358 --> 0.013837).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 21 Training: Loss: 0.015889 Acc: 0.863300  Validation Loss: 0.013707 Acc: 0.883900                                                     \n",
      "Validation loss decreased (0.013837 --> 0.013707).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 22 Training: Loss: 0.015384 Acc: 0.867940  Validation Loss: 0.013969 Acc: 0.880000                                                     \n",
      "Epoch: 23 Training: Loss: 0.015016 Acc: 0.871760  Validation Loss: 0.014358 Acc: 0.882400                                                     \n",
      "Epoch: 24 Training: Loss: 0.014796 Acc: 0.873800  Validation Loss: 0.013486 Acc: 0.889900                                                     \n",
      "Validation loss decreased (0.013707 --> 0.013486).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 25 Training: Loss: 0.014254 Acc: 0.876820  Validation Loss: 0.013168 Acc: 0.889800                                                     \n",
      "Validation loss decreased (0.013486 --> 0.013168).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 26 Training: Loss: 0.013679 Acc: 0.882640  Validation Loss: 0.013045 Acc: 0.894400                                                     \n",
      "Validation loss decreased (0.013168 --> 0.013045).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 27 Training: Loss: 0.013604 Acc: 0.882460  Validation Loss: 0.012469 Acc: 0.896000                                                     \n",
      "Validation loss decreased (0.013045 --> 0.012469).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 28 Training: Loss: 0.013401 Acc: 0.884520  Validation Loss: 0.013094 Acc: 0.889900                                                     \n",
      "Epoch: 29 Training: Loss: 0.013370 Acc: 0.885000  Validation Loss: 0.012750 Acc: 0.890600                                                     \n",
      "Epoch: 30 Training: Loss: 0.012940 Acc: 0.888820  Validation Loss: 0.013041 Acc: 0.893000                                                     \n",
      "Epoch: 31 Training: Loss: 0.012552 Acc: 0.890500  Validation Loss: 0.012404 Acc: 0.899700                                                     \n",
      "Validation loss decreased (0.012469 --> 0.012404).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 32 Training: Loss: 0.012547 Acc: 0.891140  Validation Loss: 0.012458 Acc: 0.895000                                                     \n",
      "Epoch: 33 Training: Loss: 0.012176 Acc: 0.894460  Validation Loss: 0.012415 Acc: 0.895300                                                     \n",
      "Epoch: 34 Training: Loss: 0.011869 Acc: 0.896920  Validation Loss: 0.012123 Acc: 0.901200                                                     \n",
      "Validation loss decreased (0.012404 --> 0.012123).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 35 Training: Loss: 0.011659 Acc: 0.900080  Validation Loss: 0.011976 Acc: 0.901200                                                     \n",
      "Validation loss decreased (0.012123 --> 0.011976).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 36 Training: Loss: 0.011538 Acc: 0.900340  Validation Loss: 0.012864 Acc: 0.896200                                                     \n",
      "Epoch: 37 Training: Loss: 0.011430 Acc: 0.901600  Validation Loss: 0.011147 Acc: 0.908400                                                     \n",
      "Validation loss decreased (0.011976 --> 0.011147).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 38 Training: Loss: 0.010948 Acc: 0.904840  Validation Loss: 0.012835 Acc: 0.898300                                                     \n",
      "Epoch: 39 Training: Loss: 0.010917 Acc: 0.904660  Validation Loss: 0.011010 Acc: 0.910900                                                     \n",
      "Validation loss decreased (0.011147 --> 0.011010).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 40 Training: Loss: 0.008000 Acc: 0.931380  Validation Loss: 0.009379 Acc: 0.922500                                                     \n",
      "Validation loss decreased (0.011010 --> 0.009379).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 41 Training: Loss: 0.007274 Acc: 0.936800  Validation Loss: 0.009234 Acc: 0.925400                                                     \n",
      "Validation loss decreased (0.009379 --> 0.009234).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 42 Training: Loss: 0.007025 Acc: 0.937700  Validation Loss: 0.009210 Acc: 0.925100                                                     \n",
      "Validation loss decreased (0.009234 --> 0.009210).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 43 Training: Loss: 0.007014 Acc: 0.938800  Validation Loss: 0.009468 Acc: 0.923400                                                     \n",
      "Epoch: 44 Training: Loss: 0.006717 Acc: 0.942220  Validation Loss: 0.009465 Acc: 0.924300                                                     \n",
      "Epoch: 45 Training: Loss: 0.006073 Acc: 0.949300  Validation Loss: 0.008821 Acc: 0.928800                                                     \n",
      "Validation loss decreased (0.009210 --> 0.008821).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 46 Training: Loss: 0.005793 Acc: 0.950100  Validation Loss: 0.008686 Acc: 0.926600                                                     \n",
      "Validation loss decreased (0.008821 --> 0.008686).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 47 Training: Loss: 0.005672 Acc: 0.951280  Validation Loss: 0.008788 Acc: 0.928800                                                     \n",
      "Epoch: 48 Training: Loss: 0.005451 Acc: 0.954060  Validation Loss: 0.008749 Acc: 0.929400                                                     \n",
      "Epoch: 49 Training: Loss: 0.005439 Acc: 0.953100  Validation Loss: 0.008729 Acc: 0.929500                                                     \n",
      "Epoch: 50 Training: Loss: 0.005326 Acc: 0.954800  Validation Loss: 0.008697 Acc: 0.930000                                                     \n",
      "Epoch: 51 Training: Loss: 0.005212 Acc: 0.956240  Validation Loss: 0.008571 Acc: 0.930100                                                     \n",
      "Validation loss decreased (0.008686 --> 0.008571).  Saving model to models_data/resnet18_cifar10\\model1\n",
      "Epoch: 52 Training: Loss: 0.005179 Acc: 0.955840  Validation Loss: 0.008595 Acc: 0.929400                                                     \n",
      "Epoch: 53 Training: Loss: 0.005089 Acc: 0.956900  Validation Loss: 0.008821 Acc: 0.930900                                                     \n",
      "Epoch: 54 Training: Loss: 0.005203 Acc: 0.955360  Validation Loss: 0.008683 Acc: 0.929300                                                     \n",
      "Epoch: 55 Training: Loss: 0.005073 Acc: 0.956480  Validation Loss: 0.008678 Acc: 0.929900                                                     \n",
      "Epoch: 56 Training: Loss: 0.005073 Acc: 0.956820  Validation Loss: 0.008713 Acc: 0.930300                                                     \n",
      "Epoch: 57 Training: Loss: 0.005100 Acc: 0.955860  Validation Loss: 0.008760 Acc: 0.928300                                                     \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 58 Training: Loss: 0.005092 Acc: 0.956520  Validation Loss: 0.008785 Acc: 0.927900                                                     \n",
      "Epoch: 59 Training: Loss: 0.004972 Acc: 0.957880  Validation Loss: 0.008763 Acc: 0.929300                                                     \n",
      "Test Loss: 0.008763                                                                                                                       \n",
      "Accuracy: 0.9292999999999948\n"
     ]
    }
   ],
   "source": [
    "# self.model: Module = ResNet18(10)\n",
    "# self.optimizer: torch.optim.SGD = optim.SGD(self.model.parameters(), lr=1e-3, momentum=.9)  # lr=1e-1\n",
    "# self.scheduler: torch.optim.lr_scheduler.MultiStepLR = \\\n",
    "#             optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=[40, 45, 50], gamma=0.3)\n",
    "model1 = ModelManager(10, load=False, dir_=NOTEBOOK_NAME, model_name='model1')\n",
    "print(model1.model)\n",
    "# lr*.1 in epoch: 16\n",
    "model1.train(loader_train, loader_test, loader_test, 60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Epoch: 0 Training: Loss: 0.065998 Acc: 0.388000  Validation Loss: 0.053423 Acc: 0.508100                                                     \n",
      "Validation loss decreased (inf --> 0.053423).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 1 Training: Loss: 0.052121 Acc: 0.529400  Validation Loss: 0.046614 Acc: 0.590200                                                     \n",
      "Validation loss decreased (0.053423 --> 0.046614).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 2 Training: Loss: 0.044821 Acc: 0.598720  Validation Loss: 0.036691 Acc: 0.674000                                                      \n",
      "Validation loss decreased (0.046614 --> 0.036691).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 3 Training: Loss: 0.039590 Acc: 0.650340  Validation Loss: 0.031681 Acc: 0.717300                                                      \n",
      "Validation loss decreased (0.036691 --> 0.031681).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 4 Training: Loss: 0.036314 Acc: 0.678780  Validation Loss: 0.028820 Acc: 0.747900                                                      \n",
      "Validation loss decreased (0.031681 --> 0.028820).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 5 Training: Loss: 0.032913 Acc: 0.709780  Validation Loss: 0.025815 Acc: 0.775200                                                      \n",
      "Validation loss decreased (0.028820 --> 0.025815).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 6 Training: Loss: 0.030389 Acc: 0.734220  Validation Loss: 0.024805 Acc: 0.783000                                                      \n",
      "Validation loss decreased (0.025815 --> 0.024805).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 7 Training: Loss: 0.028872 Acc: 0.748200  Validation Loss: 0.024803 Acc: 0.783100                                                      \n",
      "Validation loss decreased (0.024805 --> 0.024803).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 8 Training: Loss: 0.027161 Acc: 0.764120  Validation Loss: 0.022560 Acc: 0.805500                                                      \n",
      "Validation loss decreased (0.024803 --> 0.022560).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 9 Training: Loss: 0.025620 Acc: 0.778440  Validation Loss: 0.021149 Acc: 0.819600                                                      \n",
      "Validation loss decreased (0.022560 --> 0.021149).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 10 Training: Loss: 0.024460 Acc: 0.785220  Validation Loss: 0.020336 Acc: 0.823500                                                      \n",
      "Validation loss decreased (0.021149 --> 0.020336).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 11 Training: Loss: 0.023723 Acc: 0.794260  Validation Loss: 0.019602 Acc: 0.832300                                                      \n",
      "Validation loss decreased (0.020336 --> 0.019602).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 12 Training: Loss: 0.022394 Acc: 0.805580  Validation Loss: 0.019817 Acc: 0.830100                                                      \n",
      "Epoch: 13 Training: Loss: 0.021488 Acc: 0.812020  Validation Loss: 0.018957 Acc: 0.836500                                                      \n",
      "Validation loss decreased (0.019602 --> 0.018957).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 14 Training: Loss: 0.020753 Acc: 0.819760  Validation Loss: 0.017715 Acc: 0.844000                                                      \n",
      "Validation loss decreased (0.018957 --> 0.017715).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 15 Training: Loss: 0.019982 Acc: 0.826360  Validation Loss: 0.017495 Acc: 0.849300                                                      \n",
      "Validation loss decreased (0.017715 --> 0.017495).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 16 Training: Loss: 0.019482 Acc: 0.828400  Validation Loss: 0.015984 Acc: 0.862600                                                      \n",
      "Validation loss decreased (0.017495 --> 0.015984).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 17 Training: Loss: 0.018819 Acc: 0.836340  Validation Loss: 0.016621 Acc: 0.858700                                                      \n",
      "Epoch: 18 Training: Loss: 0.017946 Acc: 0.842600  Validation Loss: 0.016795 Acc: 0.855700                                                      \n",
      "Epoch: 19 Training: Loss: 0.017350 Acc: 0.847820  Validation Loss: 0.015322 Acc: 0.866900                                                      \n",
      "Validation loss decreased (0.015984 --> 0.015322).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 20 Training: Loss: 0.017038 Acc: 0.851660  Validation Loss: 0.015106 Acc: 0.872400                                                      \n",
      "Validation loss decreased (0.015322 --> 0.015106).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 21 Training: Loss: 0.016555 Acc: 0.855860  Validation Loss: 0.015187 Acc: 0.871400                                                      \n",
      "Epoch: 22 Training: Loss: 0.016062 Acc: 0.858980  Validation Loss: 0.015036 Acc: 0.871100                                                      \n",
      "Validation loss decreased (0.015106 --> 0.015036).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 23 Training: Loss: 0.015428 Acc: 0.867440  Validation Loss: 0.014689 Acc: 0.877000                                                      \n",
      "Validation loss decreased (0.015036 --> 0.014689).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 24 Training: Loss: 0.014985 Acc: 0.868860  Validation Loss: 0.014168 Acc: 0.881600                                                      \n",
      "Validation loss decreased (0.014689 --> 0.014168).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 25 Training: Loss: 0.014641 Acc: 0.871900  Validation Loss: 0.014099 Acc: 0.878700                                                      \n",
      "Validation loss decreased (0.014168 --> 0.014099).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 26 Training: Loss: 0.014246 Acc: 0.876180  Validation Loss: 0.013875 Acc: 0.882000                                                      \n",
      "Validation loss decreased (0.014099 --> 0.013875).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 27 Training: Loss: 0.013765 Acc: 0.879680  Validation Loss: 0.013329 Acc: 0.891500                                                      \n",
      "Validation loss decreased (0.013875 --> 0.013329).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 28 Training: Loss: 0.013282 Acc: 0.884660  Validation Loss: 0.013747 Acc: 0.886400                                                      \n",
      "Epoch: 29 Training: Loss: 0.013083 Acc: 0.886340  Validation Loss: 0.013463 Acc: 0.890700                                                      \n",
      "Epoch: 30 Training: Loss: 0.012976 Acc: 0.885740  Validation Loss: 0.013499 Acc: 0.887200                                                      \n",
      "Epoch: 31 Training: Loss: 0.012299 Acc: 0.893700  Validation Loss: 0.013133 Acc: 0.893000                                                      \n",
      "Validation loss decreased (0.013329 --> 0.013133).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 32 Training: Loss: 0.012090 Acc: 0.893640  Validation Loss: 0.012525 Acc: 0.896600                                                      \n",
      "Validation loss decreased (0.013133 --> 0.012525).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 33 Training: Loss: 0.011801 Acc: 0.896900  Validation Loss: 0.013181 Acc: 0.893000                                                      \n",
      "Epoch: 34 Training: Loss: 0.011672 Acc: 0.897640  Validation Loss: 0.013250 Acc: 0.889200                                                      \n",
      "Epoch: 35 Training: Loss: 0.011123 Acc: 0.903280  Validation Loss: 0.014063 Acc: 0.883900                                                      \n",
      "Epoch: 36 Training: Loss: 0.011101 Acc: 0.902680  Validation Loss: 0.013298 Acc: 0.893100                                                      \n",
      "Epoch: 37 Training: Loss: 0.010850 Acc: 0.904160  Validation Loss: 0.012778 Acc: 0.898400                                                      \n",
      "Epoch: 38 Training: Loss: 0.010251 Acc: 0.910640  Validation Loss: 0.012327 Acc: 0.899100                                                      \n",
      "Validation loss decreased (0.012525 --> 0.012327).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 39 Training: Loss: 0.010294 Acc: 0.911080  Validation Loss: 0.012461 Acc: 0.899400                                                      \n",
      "Epoch: 40 Training: Loss: 0.008139 Acc: 0.928060  Validation Loss: 0.010727 Acc: 0.910300                                                      \n",
      "Validation loss decreased (0.012327 --> 0.010727).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 41 Training: Loss: 0.007756 Acc: 0.932540  Validation Loss: 0.010807 Acc: 0.910000                                                      \n",
      "Epoch: 42 Training: Loss: 0.007507 Acc: 0.934400  Validation Loss: 0.010721 Acc: 0.911300                                                      \n",
      "Validation loss decreased (0.010727 --> 0.010721).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 43 Training: Loss: 0.007207 Acc: 0.936540  Validation Loss: 0.010780 Acc: 0.912500                                                      \n",
      "Epoch: 44 Training: Loss: 0.007239 Acc: 0.936960  Validation Loss: 0.010884 Acc: 0.911500                                                      \n",
      "Epoch: 45 Training: Loss: 0.006801 Acc: 0.940920  Validation Loss: 0.010490 Acc: 0.914900                                                      \n",
      "Validation loss decreased (0.010721 --> 0.010490).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 46 Training: Loss: 0.006597 Acc: 0.942460  Validation Loss: 0.010604 Acc: 0.912700                                                      \n",
      "Epoch: 47 Training: Loss: 0.006433 Acc: 0.944600  Validation Loss: 0.010739 Acc: 0.912300                                                      \n",
      "Epoch: 48 Training: Loss: 0.006290 Acc: 0.945600  Validation Loss: 0.010551 Acc: 0.913900                                                      \n",
      "Epoch: 49 Training: Loss: 0.006295 Acc: 0.945460  Validation Loss: 0.010727 Acc: 0.914400                                                      \n",
      "Epoch: 50 Training: Loss: 0.006274 Acc: 0.945200  Validation Loss: 0.010455 Acc: 0.915600                                                      \n",
      "Validation loss decreased (0.010490 --> 0.010455).  Saving model to models_data/resnet18_cifar10\\model2\n",
      "Epoch: 51 Training: Loss: 0.005902 Acc: 0.948360  Validation Loss: 0.010692 Acc: 0.914800                                                      \n",
      "Epoch: 52 Training: Loss: 0.006047 Acc: 0.947840  Validation Loss: 0.010607 Acc: 0.914600                                                      \n",
      "Epoch: 53 Training: Loss: 0.006077 Acc: 0.948140  Validation Loss: 0.010480 Acc: 0.915900                                                      \n",
      "Epoch: 54 Training: Loss: 0.006051 Acc: 0.947520  Validation Loss: 0.010483 Acc: 0.914000                                                      \n",
      "Epoch: 55 Training: Loss: 0.006127 Acc: 0.947140  Validation Loss: 0.010463 Acc: 0.915000                                                      \n",
      "Epoch: 56 Training: Loss: 0.006048 Acc: 0.947920  Validation Loss: 0.010564 Acc: 0.915000                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 57 Training: Loss: 0.006104 Acc: 0.946740  Validation Loss: 0.010673 Acc: 0.914900                                                      \n",
      "Epoch: 58 Training: Loss: 0.006030 Acc: 0.948720  Validation Loss: 0.010598 Acc: 0.913800                                                      \n",
      "Epoch: 59 Training: Loss: 0.005913 Acc: 0.948040  Validation Loss: 0.010644 Acc: 0.914800                                                      \n",
      "Test Loss: 0.010644                                                                                                                        \n",
      "Accuracy: 0.9147999999999955\n"
     ]
    }
   ],
   "source": [
    "# self.model = torchvision.models.resnet18(weights=None)\n",
    "# self.model.conv1 = Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "# self.model.maxpool = nn.Identity()\n",
    "# self.model.fc = Linear(512, self.num_classes, bias=True)\n",
    "# self.scheduler: torch.optim.lr_scheduler.MultiStepLR = optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=[20, 30, 40], gamma=0.3)\n",
    "model2 = ModelManager(10, load=False, dir_=NOTEBOOK_NAME, model_name='model2')\n",
    "print(model2.model)\n",
    "# lr*.1 in epoch: 16\n",
    "model2.train(loader_train, loader_test, loader_test, 60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "<torch.optim.lr_scheduler.StepLR object at 0x00000271954C4130>\n",
      "Epoch: 0 Training: Loss: 0.057969 Acc: 0.474780  Validation Loss: 0.040194 Acc: 0.640700                                                     \n",
      "Validation loss decreased (inf --> 0.040194).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 1 Training: Loss: 0.041487 Acc: 0.634120  Validation Loss: 0.031140 Acc: 0.732200                                                      \n",
      "Validation loss decreased (0.040194 --> 0.031140).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 2 Training: Loss: 0.033857 Acc: 0.702460  Validation Loss: 0.027362 Acc: 0.767100                                                      \n",
      "Validation loss decreased (0.031140 --> 0.027362).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 3 Training: Loss: 0.028926 Acc: 0.748800  Validation Loss: 0.024722 Acc: 0.790200                                                      \n",
      "Validation loss decreased (0.027362 --> 0.024722).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 4 Training: Loss: 0.025614 Acc: 0.777600  Validation Loss: 0.020442 Acc: 0.825000                                                      \n",
      "Validation loss decreased (0.024722 --> 0.020442).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 5 Training: Loss: 0.023086 Acc: 0.799940  Validation Loss: 0.019152 Acc: 0.835200                                                      \n",
      "Validation loss decreased (0.020442 --> 0.019152).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 6 Training: Loss: 0.020805 Acc: 0.821180  Validation Loss: 0.017591 Acc: 0.851700                                                      \n",
      "Validation loss decreased (0.019152 --> 0.017591).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 7 Training: Loss: 0.019382 Acc: 0.831360  Validation Loss: 0.016764 Acc: 0.857600                                                      \n",
      "Validation loss decreased (0.017591 --> 0.016764).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 8 Training: Loss: 0.018058 Acc: 0.842900  Validation Loss: 0.014729 Acc: 0.875800                                                      \n",
      "Validation loss decreased (0.016764 --> 0.014729).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 9 Training: Loss: 0.016652 Acc: 0.855180  Validation Loss: 0.015271 Acc: 0.871600                                                      \n",
      "Epoch: 10 Training: Loss: 0.015656 Acc: 0.863140  Validation Loss: 0.013329 Acc: 0.887100                                                      \n",
      "Validation loss decreased (0.014729 --> 0.013329).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 11 Training: Loss: 0.014733 Acc: 0.871180  Validation Loss: 0.012885 Acc: 0.890700                                                      \n",
      "Validation loss decreased (0.013329 --> 0.012885).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 12 Training: Loss: 0.013844 Acc: 0.881000  Validation Loss: 0.012761 Acc: 0.891000                                                      \n",
      "Validation loss decreased (0.012885 --> 0.012761).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 13 Training: Loss: 0.013140 Acc: 0.886040  Validation Loss: 0.012066 Acc: 0.899600                                                      \n",
      "Validation loss decreased (0.012761 --> 0.012066).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 14 Training: Loss: 0.012335 Acc: 0.892240  Validation Loss: 0.012191 Acc: 0.900300                                                      \n",
      "Epoch: 15 Training: Loss: 0.011761 Acc: 0.898120  Validation Loss: 0.012262 Acc: 0.894100                                                      \n",
      "Epoch: 16 Training: Loss: 0.011095 Acc: 0.903340  Validation Loss: 0.011233 Acc: 0.905300                                                      \n",
      "Validation loss decreased (0.012066 --> 0.011233).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 17 Training: Loss: 0.010696 Acc: 0.906580  Validation Loss: 0.011814 Acc: 0.905300                                                      \n",
      "Epoch: 18 Training: Loss: 0.010033 Acc: 0.912740  Validation Loss: 0.011477 Acc: 0.903800                                                      \n",
      "Epoch: 19 Training: Loss: 0.009657 Acc: 0.915040  Validation Loss: 0.011090 Acc: 0.908300                                                      \n",
      "Validation loss decreased (0.011233 --> 0.011090).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 20 Training: Loss: 0.009267 Acc: 0.918320  Validation Loss: 0.010894 Acc: 0.912000                                                      \n",
      "Validation loss decreased (0.011090 --> 0.010894).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 21 Training: Loss: 0.008913 Acc: 0.921620  Validation Loss: 0.010673 Acc: 0.914100                                                      \n",
      "Validation loss decreased (0.010894 --> 0.010673).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 22 Training: Loss: 0.008527 Acc: 0.925420  Validation Loss: 0.011321 Acc: 0.908000                                                      \n",
      "Epoch: 23 Training: Loss: 0.008188 Acc: 0.927780  Validation Loss: 0.011232 Acc: 0.910500                                                      \n",
      "Epoch: 24 Training: Loss: 0.007713 Acc: 0.931840  Validation Loss: 0.010619 Acc: 0.913400                                                      \n",
      "Validation loss decreased (0.010673 --> 0.010619).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 25 Training: Loss: 0.007419 Acc: 0.934760  Validation Loss: 0.011377 Acc: 0.913600                                                      \n",
      "Epoch: 26 Training: Loss: 0.007158 Acc: 0.937220  Validation Loss: 0.010412 Acc: 0.918000                                                      \n",
      "Validation loss decreased (0.010619 --> 0.010412).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 27 Training: Loss: 0.007025 Acc: 0.938580  Validation Loss: 0.010947 Acc: 0.916600                                                      \n",
      "Epoch: 28 Training: Loss: 0.006544 Acc: 0.942860  Validation Loss: 0.010893 Acc: 0.916700                                                      \n",
      "Epoch: 29 Training: Loss: 0.006612 Acc: 0.942560  Validation Loss: 0.009952 Acc: 0.920900                                                      \n",
      "Validation loss decreased (0.010412 --> 0.009952).  Saving model to models_data/resnet18_cifar10\\model3\n",
      "Epoch: 30 Training: Loss: 0.006269 Acc: 0.945200  Validation Loss: 0.010686 Acc: 0.920000                                                      \n",
      "Epoch: 31 Training: Loss: 0.005999 Acc: 0.946760  Validation Loss: 0.010633 Acc: 0.919700                                                      \n",
      "Epoch: 32 Training: Loss: 0.005757 Acc: 0.948760  Validation Loss: 0.010630 Acc: 0.921400                                                      \n",
      "Epoch: 33 Training: Loss: 0.005515 Acc: 0.950620  Validation Loss: 0.011338 Acc: 0.919700                                                      \n",
      "Epoch: 34 Training: Loss: 0.005449 Acc: 0.952540  Validation Loss: 0.010800 Acc: 0.922100                                                      \n",
      "Epoch: 35 Training: Loss: 0.005348 Acc: 0.952180  Validation Loss: 0.010622 Acc: 0.923300                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 36 Training: Loss: 0.005173 Acc: 0.953980  Validation Loss: 0.010662 Acc: 0.921100                                                      \n",
      "Epoch: 37 Training: Loss: 0.005002 Acc: 0.956220  Validation Loss: 0.011064 Acc: 0.922700                                                      \n",
      "Epoch: 38 Training: Loss: 0.004879 Acc: 0.957280  Validation Loss: 0.011291 Acc: 0.920400                                                      \n",
      "Epoch: 39 Training: Loss: 0.004798 Acc: 0.958140  Validation Loss: 0.011129 Acc: 0.919300                                                      \n",
      "Epoch: 40 Training: Loss: 0.004753 Acc: 0.958960  Validation Loss: 0.011387 Acc: 0.920800                                                      \n",
      "Epoch: 41 Training: Loss: 0.004495 Acc: 0.960440  Validation Loss: 0.011155 Acc: 0.923400                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 42 Training: Loss: 0.004439 Acc: 0.960180  Validation Loss: 0.011834 Acc: 0.920600                                                      \n",
      "Epoch: 43 Training: Loss: 0.004350 Acc: 0.962020  Validation Loss: 0.011458 Acc: 0.923600                                                      \n",
      "Epoch: 44 Training: Loss: 0.004111 Acc: 0.963680  Validation Loss: 0.012041 Acc: 0.922200                                                      \n",
      "Epoch: 45 Training: Loss: 0.004226 Acc: 0.963240  Validation Loss: 0.011121 Acc: 0.925800                                                      \n",
      "Epoch: 46 Training: Loss: 0.004084 Acc: 0.964160  Validation Loss: 0.010450 Acc: 0.929400                                                      \n",
      "Epoch: 47 Training: Loss: 0.003979 Acc: 0.965700  Validation Loss: 0.011331 Acc: 0.927100                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 48 Training: Loss: 0.003801 Acc: 0.966540  Validation Loss: 0.010739 Acc: 0.930600                                                      \n",
      "Epoch: 49 Training: Loss: 0.003727 Acc: 0.967620  Validation Loss: 0.011939 Acc: 0.922400                                                      \n",
      "Epoch: 50 Training: Loss: 0.003779 Acc: 0.967700  Validation Loss: 0.010968 Acc: 0.927500                                                      \n",
      "Epoch: 51 Training: Loss: 0.003739 Acc: 0.967300  Validation Loss: 0.011646 Acc: 0.924900                                                      \n",
      "Epoch: 52 Training: Loss: 0.003409 Acc: 0.969900  Validation Loss: 0.011711 Acc: 0.923900                                                      \n",
      "Epoch: 53 Training: Loss: 0.003609 Acc: 0.969140  Validation Loss: 0.012008 Acc: 0.925700                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 54 Training: Loss: 0.003349 Acc: 0.969920  Validation Loss: 0.012142 Acc: 0.922900                                                      \n",
      "Epoch: 55 Training: Loss: 0.003447 Acc: 0.970240  Validation Loss: 0.011003 Acc: 0.931600                                                      \n",
      "Epoch: 56 Training: Loss: 0.003388 Acc: 0.971400  Validation Loss: 0.011773 Acc: 0.929700                                                      \n",
      "Epoch: 57 Training: Loss: 0.003189 Acc: 0.971800  Validation Loss: 0.012104 Acc: 0.926600                                                      \n",
      "Epoch: 58 Training: Loss: 0.003266 Acc: 0.971820  Validation Loss: 0.012377 Acc: 0.926700                                                      \n",
      "Epoch: 59 Training: Loss: 0.003064 Acc: 0.973880  Validation Loss: 0.012048 Acc: 0.928300                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Test Loss: 0.012048                                                                                                                        \n",
      "Accuracy: 0.9282999999999946\n"
     ]
    }
   ],
   "source": [
    "# self.model = torchvision.models.resnet18(weights=None)\n",
    "# self.model.conv1 = Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "# self.model.maxpool = nn.Identity()\n",
    "# self.model.fc = Linear(512, self.num_classes, bias=True)\n",
    "# self.optimizer: torch.optim.Adam = optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "# self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=100, gamma=0.95)\n",
    "# sched:15\n",
    "model3 = ModelManager(10, load=False, dir_=NOTEBOOK_NAME, model_name='model3')\n",
    "print(model3.model)\n",
    "print(model3.optimizer)\n",
    "print(model3.scheduler)\n",
    "# lr*.1 in epoch: 16\n",
    "model3.train(loader_train, loader_test, loader_test, 60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "<torch.optim.lr_scheduler.StepLR object at 0x0000020E95D28CA0>\n",
      "Epoch: 0 Training: Loss: 0.071045 Acc: 0.345940  Validation Loss: 0.056697 Acc: 0.471500                                                     \n",
      "Validation loss decreased (inf --> 0.056697).  Saving model to models_data/resnet18_cifar10\\model4\n",
      "Epoch: 1 Training: Loss: 0.053136 Acc: 0.519320  Validation Loss: 0.042647 Acc: 0.617200                                                     \n",
      "Validation loss decreased (0.056697 --> 0.042647).  Saving model to models_data/resnet18_cifar10\\model4\n",
      "Epoch: 2 Training: Loss: 0.043499 Acc: 0.614540  Validation Loss: 0.035091 Acc: 0.686800                                                      \n",
      "Validation loss decreased (0.042647 --> 0.035091).  Saving model to models_data/resnet18_cifar10\\model4\n",
      "Epoch: 3 Training: Loss: 0.037128 Acc: 0.671240  Validation Loss: 0.030094 Acc: 0.735000                                                      \n",
      "Validation loss decreased (0.035091 --> 0.030094).  Saving model to models_data/resnet18_cifar10\\model4\n",
      "Epoch: 4 Training: Loss: 0.032483 Acc: 0.714460  Validation Loss: 0.026895 Acc: 0.764200                                                      \n",
      "Validation loss decreased (0.030094 --> 0.026895).  Saving model to models_data/resnet18_cifar10\\model4\n",
      "Epoch: 5 Training: Loss: 0.028726 Acc: 0.748820  Validation Loss: 0.023620 Acc: 0.800500                                                      \n",
      "Validation loss decreased (0.026895 --> 0.023620).  Saving model to models_data/resnet18_cifar10\\model4\n",
      "Epoch: 6 Training: Loss: 0.025664 Acc: 0.774040  Validation Loss: 0.021844 Acc: 0.812800                                                      \n",
      "Validation loss decreased (0.023620 --> 0.021844).  Saving model to models_data/resnet18_cifar10\\model4\n",
      "Epoch: 7 Training: Loss: 0.023308 Acc: 0.795220  Validation Loss: 0.019539 Acc: 0.825600                                                      \n",
      "Validation loss decreased (0.021844 --> 0.019539).  Saving model to models_data/resnet18_cifar10\\model4\n",
      "Epoch: 8 Training: Loss: 0.021617 Acc: 0.811680  Validation Loss: 0.018381 Acc: 0.842700                                                      \n",
      "Validation loss decreased (0.019539 --> 0.018381).  Saving model to models_data/resnet18_cifar10\\model4\n",
      "Epoch: 9 Training: Loss: 0.020150 Acc: 0.825520  Validation Loss: 0.017356 Acc: 0.853700                                                      \n",
      "Validation loss decreased (0.018381 --> 0.017356).  Saving model to models_data/resnet18_cifar10\\model4\n",
      "Epoch: 10 Training: Loss: nan Acc: 0.428120  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 11 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 12 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 13 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 14 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 15 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 16 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 17 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 18 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 19 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 20 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 21 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 22 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 23 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 24 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 25 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 26 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 27 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 28 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 29 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 30 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 31 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 32 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 33 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 34 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 35 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 36 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 37 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 38 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 39 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 40 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 41 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 42 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 43 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 44 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 45 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 46 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 47 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 48 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 49 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 50 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Epoch: 51 Training: Loss: nan Acc: 0.100000  Validation Loss: nan Acc: 0.100000                                                             \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch 52 Train: ████████████████████████████████████                          1200/2000 [00:26<00:17, 46.47 batch/s, acc=6.08%, loss=nan]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(model4\u001B[38;5;241m.\u001B[39mscheduler)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# lr*.1 in epoch: 16\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m \u001B[43mmodel4\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloader_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloader_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloader_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m60\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Data-pruning\\code\\train.py:304\u001B[0m, in \u001B[0;36mModelManager.train\u001B[1;34m(self, train_loader, valid_loader, test_loader, epochs, verbose)\u001B[0m\n\u001B[0;32m    302\u001B[0m \u001B[38;5;66;03m# with torch.autograd.profiler.profile(enabled=False), torch.autograd.detect_anomaly(check_nan=False):\u001B[39;00m\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepochs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepochs \u001B[38;5;241m+\u001B[39m epochs):\n\u001B[1;32m--> 304\u001B[0m     _, _, loss, acc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTRAIN\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    305\u001B[0m     loss_train\u001B[38;5;241m.\u001B[39mappend(loss), acc_train\u001B[38;5;241m.\u001B[39mappend(acc)\n\u001B[0;32m    306\u001B[0m     _, _, loss, acc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_epoch(valid_loader, Mode\u001B[38;5;241m.\u001B[39mVALIDATE)\n",
      "File \u001B[1;32m~\\Documents\\Data-pruning\\code\\train.py:268\u001B[0m, in \u001B[0;36mModelManager.run_epoch\u001B[1;34m(self, loader, mode)\u001B[0m\n\u001B[0;32m    265\u001B[0m loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss_batch\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;241m/\u001B[39m len_dataset\n\u001B[0;32m    267\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m Mode\u001B[38;5;241m.\u001B[39mTRAIN:\n\u001B[1;32m--> 268\u001B[0m     \u001B[43mloss_batch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    269\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    271\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m Mode\u001B[38;5;241m.\u001B[39mTEST:\n",
      "File \u001B[1;32m~\\Documents\\Data-pruning\\venv\\lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Data-pruning\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# self.model = torchvision.models.resnet18(weights=None)\n",
    "# self.model.conv1 = Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "# self.model.maxpool = nn.Identity()\n",
    "# self.model.fc = Linear(512, self.num_classes, bias=True)\n",
    "# self.optimizer: torch.optim.Adam = optim.Adam(self.model.parameters(), lr=1e-2)\n",
    "# self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=1, gamma=0.93)\n",
    "# sched:15\n",
    "model4 = ModelManager(10, load=False, dir_=NOTEBOOK_NAME, model_name='model4')\n",
    "print(model4.model)\n",
    "print(model4.optimizer)\n",
    "print(model4.scheduler)\n",
    "# lr*.1 in epoch: 16\n",
    "model4.train(loader_train, loader_test, loader_test, 60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "0.85\n",
      "Epoch: 0 Training: Loss: 0.070806 Acc: 0.350420  Validation Loss: 0.058596 Acc: 0.462900                                                     \n",
      "Validation loss decreased (inf --> 0.058596).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 1 Training: Loss: 0.050829 Acc: 0.546220  Validation Loss: 0.041889 Acc: 0.622300                                                     \n",
      "Validation loss decreased (0.058596 --> 0.041889).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 2 Training: Loss: 0.040845 Acc: 0.638160  Validation Loss: 0.035695 Acc: 0.690000                                                      \n",
      "Validation loss decreased (0.041889 --> 0.035695).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 3 Training: Loss: 0.035238 Acc: 0.690520  Validation Loss: 0.031904 Acc: 0.722700                                                      \n",
      "Validation loss decreased (0.035695 --> 0.031904).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 4 Training: Loss: 0.030758 Acc: 0.729320  Validation Loss: 0.024038 Acc: 0.792700                                                      \n",
      "Validation loss decreased (0.031904 --> 0.024038).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 5 Training: Loss: 0.026759 Acc: 0.765560  Validation Loss: 0.022136 Acc: 0.810000                                                      \n",
      "Validation loss decreased (0.024038 --> 0.022136).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 6 Training: Loss: 0.024163 Acc: 0.788020  Validation Loss: 0.020320 Acc: 0.827600                                                      \n",
      "Validation loss decreased (0.022136 --> 0.020320).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 7 Training: Loss: 0.022131 Acc: 0.806140  Validation Loss: 0.018518 Acc: 0.841700                                                      \n",
      "Validation loss decreased (0.020320 --> 0.018518).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 8 Training: Loss: 0.020270 Acc: 0.822180  Validation Loss: 0.017460 Acc: 0.850600                                                      \n",
      "Validation loss decreased (0.018518 --> 0.017460).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 9 Training: Loss: 0.018876 Acc: 0.836040  Validation Loss: 0.016530 Acc: 0.857700                                                      \n",
      "Validation loss decreased (0.017460 --> 0.016530).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 10 Training: Loss: 0.017560 Acc: 0.846240  Validation Loss: 0.016087 Acc: 0.860600                                                      \n",
      "Validation loss decreased (0.016530 --> 0.016087).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 11 Training: Loss: 0.016608 Acc: 0.854620  Validation Loss: 0.015198 Acc: 0.871000                                                      \n",
      "Validation loss decreased (0.016087 --> 0.015198).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 12 Training: Loss: 0.015710 Acc: 0.862240  Validation Loss: 0.015000 Acc: 0.872000                                                      \n",
      "Validation loss decreased (0.015198 --> 0.015000).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 13 Training: Loss: 0.014943 Acc: 0.870120  Validation Loss: 0.014660 Acc: 0.876100                                                      \n",
      "Validation loss decreased (0.015000 --> 0.014660).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 14 Training: Loss: 0.014282 Acc: 0.873100  Validation Loss: 0.013967 Acc: 0.883400                                                      \n",
      "Validation loss decreased (0.014660 --> 0.013967).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 15 Training: Loss: 0.013727 Acc: 0.878060  Validation Loss: 0.014185 Acc: 0.881700                                                      \n",
      "Epoch: 16 Training: Loss: 0.013243 Acc: 0.884720  Validation Loss: 0.013702 Acc: 0.883800                                                      \n",
      "Validation loss decreased (0.013967 --> 0.013702).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 17 Training: Loss: 0.012901 Acc: 0.886420  Validation Loss: 0.013618 Acc: 0.888700                                                      \n",
      "Validation loss decreased (0.013702 --> 0.013618).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 18 Training: Loss: 0.012413 Acc: 0.891440  Validation Loss: 0.013705 Acc: 0.885800                                                      \n",
      "Epoch: 19 Training: Loss: 0.012081 Acc: 0.892560  Validation Loss: 0.013322 Acc: 0.888300                                                      \n",
      "Validation loss decreased (0.013618 --> 0.013322).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 20 Training: Loss: 0.011820 Acc: 0.896160  Validation Loss: 0.013533 Acc: 0.889900                                                      \n",
      "Epoch: 21 Training: Loss: 0.011533 Acc: 0.897400  Validation Loss: 0.013396 Acc: 0.891200                                                      \n",
      "Epoch: 22 Training: Loss: 0.011364 Acc: 0.899100  Validation Loss: 0.013401 Acc: 0.889400                                                      \n",
      "Epoch: 23 Training: Loss: 0.011248 Acc: 0.902320  Validation Loss: 0.013395 Acc: 0.889100                                                      \n",
      "Epoch: 24 Training: Loss: 0.010942 Acc: 0.904260  Validation Loss: 0.013356 Acc: 0.890600                                                      \n",
      "Epoch: 25 Training: Loss: 0.010987 Acc: 0.902180  Validation Loss: 0.013120 Acc: 0.890400                                                      \n",
      "Validation loss decreased (0.013322 --> 0.013120).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 26 Training: Loss: 0.010904 Acc: 0.903060  Validation Loss: 0.013143 Acc: 0.891700                                                      \n",
      "Epoch: 27 Training: Loss: 0.010766 Acc: 0.903820  Validation Loss: 0.013143 Acc: 0.893200                                                      \n",
      "Epoch: 28 Training: Loss: 0.010625 Acc: 0.905600  Validation Loss: 0.013097 Acc: 0.892500                                                      \n",
      "Validation loss decreased (0.013120 --> 0.013097).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 29 Training: Loss: 0.010675 Acc: 0.904900  Validation Loss: 0.013010 Acc: 0.893800                                                      \n",
      "Validation loss decreased (0.013097 --> 0.013010).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 30 Training: Loss: 0.010493 Acc: 0.906800  Validation Loss: 0.012947 Acc: 0.893500                                                      \n",
      "Validation loss decreased (0.013010 --> 0.012947).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 31 Training: Loss: 0.010446 Acc: 0.907600  Validation Loss: 0.013009 Acc: 0.891500                                                      \n",
      "Epoch: 32 Training: Loss: 0.010501 Acc: 0.907300  Validation Loss: 0.012921 Acc: 0.892800                                                      \n",
      "Validation loss decreased (0.012947 --> 0.012921).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 33 Training: Loss: 0.010406 Acc: 0.907840  Validation Loss: 0.013000 Acc: 0.892800                                                      \n",
      "Epoch: 34 Training: Loss: 0.010428 Acc: 0.908180  Validation Loss: 0.012963 Acc: 0.892500                                                      \n",
      "Epoch: 35 Training: Loss: 0.010220 Acc: 0.909900  Validation Loss: 0.012874 Acc: 0.895000                                                      \n",
      "Validation loss decreased (0.012921 --> 0.012874).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 36 Training: Loss: 0.010405 Acc: 0.907460  Validation Loss: 0.012930 Acc: 0.893000                                                      \n",
      "Epoch: 37 Training: Loss: 0.010314 Acc: 0.909420  Validation Loss: 0.012971 Acc: 0.891700                                                      \n",
      "Epoch: 38 Training: Loss: 0.010193 Acc: 0.909520  Validation Loss: 0.012960 Acc: 0.892700                                                      \n",
      "Epoch: 39 Training: Loss: 0.010256 Acc: 0.908340  Validation Loss: 0.012850 Acc: 0.893300                                                      \n",
      "Validation loss decreased (0.012874 --> 0.012850).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 40 Training: Loss: 0.010214 Acc: 0.910000  Validation Loss: 0.012898 Acc: 0.893200                                                      \n",
      "Epoch: 41 Training: Loss: 0.010332 Acc: 0.909320  Validation Loss: 0.012934 Acc: 0.893600                                                      \n",
      "Epoch: 42 Training: Loss: 0.010250 Acc: 0.908080  Validation Loss: 0.012982 Acc: 0.893900                                                      \n",
      "Epoch: 43 Training: Loss: 0.010049 Acc: 0.910460  Validation Loss: 0.012997 Acc: 0.893600                                                      \n",
      "Epoch: 44 Training: Loss: 0.010180 Acc: 0.908860  Validation Loss: 0.012879 Acc: 0.894500                                                      \n",
      "Epoch: 45 Training: Loss: 0.010151 Acc: 0.909740  Validation Loss: 0.013000 Acc: 0.891700                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 46 Training: Loss: 0.010072 Acc: 0.910980  Validation Loss: 0.012871 Acc: 0.894100                                                      \n",
      "Epoch: 47 Training: Loss: 0.010172 Acc: 0.910240  Validation Loss: 0.012808 Acc: 0.893400                                                      \n",
      "Validation loss decreased (0.012850 --> 0.012808).  Saving model to models_data/resnet18_cifar10\\model5\n",
      "Epoch: 48 Training: Loss: 0.010135 Acc: 0.911260  Validation Loss: 0.012859 Acc: 0.894000                                                      \n",
      "Epoch: 49 Training: Loss: 0.010190 Acc: 0.908980  Validation Loss: 0.012969 Acc: 0.893800                                                      \n",
      "Epoch: 50 Training: Loss: 0.010042 Acc: 0.910800  Validation Loss: 0.013009 Acc: 0.892200                                                      \n",
      "Epoch: 51 Training: Loss: 0.010133 Acc: 0.909240  Validation Loss: 0.012933 Acc: 0.894300                                                      \n",
      "Epoch: 52 Training: Loss: 0.010168 Acc: 0.909060  Validation Loss: 0.012929 Acc: 0.893700                                                      \n",
      "Epoch: 53 Training: Loss: 0.010146 Acc: 0.910380  Validation Loss: 0.012980 Acc: 0.892700                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 54 Training: Loss: 0.010384 Acc: 0.907640  Validation Loss: 0.012933 Acc: 0.893500                                                      \n",
      "Epoch: 55 Training: Loss: 0.010240 Acc: 0.908240  Validation Loss: 0.012880 Acc: 0.893300                                                      \n",
      "Epoch: 56 Training: Loss: 0.010055 Acc: 0.911220  Validation Loss: 0.012903 Acc: 0.894000                                                      \n",
      "Epoch: 57 Training: Loss: 0.010025 Acc: 0.909700  Validation Loss: 0.012920 Acc: 0.893000                                                      \n",
      "Epoch: 58 Training: Loss: 0.010084 Acc: 0.910640  Validation Loss: 0.013014 Acc: 0.892500                                                      \n",
      "Epoch: 59 Training: Loss: 0.010263 Acc: 0.909280  Validation Loss: 0.012920 Acc: 0.893100                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Test Loss: 0.012920                                                                                                                        \n",
      "Accuracy: 0.8930999999999961\n"
     ]
    }
   ],
   "source": [
    "# self.model = torchvision.models.resnet18(weights=None)\n",
    "# self.model.conv1 = Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "# self.model.maxpool = nn.Identity()\n",
    "# self.model.fc = Linear(512, self.num_classes, bias=True)\n",
    "# self.optimizer: torch.optim.Adam = optim.Adam(self.model.parameters(), lr=1e-2)\n",
    "# self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=1, gamma=0.85)\n",
    "# sched:15\n",
    "model5 = ModelManager(10, load=False, dir_=NOTEBOOK_NAME, model_name='model5')\n",
    "print(model5.model)\n",
    "print(model5.optimizer)\n",
    "print(model5.scheduler.gamma)\n",
    "# lr*.1 in epoch: 16\n",
    "model5.train(loader_train, loader_test, loader_test, 60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "0.85 <bound method _LRScheduler.step of <torch.optim.lr_scheduler.StepLR object at 0x000001B0CFCE8220>>\n",
      "Epoch: 0 Training: Loss: 0.058417 Acc: 0.468300  Validation Loss: 0.044035 Acc: 0.605300                                                     \n",
      "Validation loss decreased (inf --> 0.044035).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 1 Training: Loss: 0.043859 Acc: 0.608220  Validation Loss: 0.034347 Acc: 0.698800                                                      \n",
      "Validation loss decreased (0.044035 --> 0.034347).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 2 Training: Loss: 0.036570 Acc: 0.678500  Validation Loss: 0.031631 Acc: 0.721600                                                      \n",
      "Validation loss decreased (0.034347 --> 0.031631).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 3 Training: Loss: 0.031801 Acc: 0.722140  Validation Loss: 0.024598 Acc: 0.786300                                                      \n",
      "Validation loss decreased (0.031631 --> 0.024598).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 4 Training: Loss: 0.028704 Acc: 0.751360  Validation Loss: 0.024412 Acc: 0.790000                                                      \n",
      "Validation loss decreased (0.024598 --> 0.024412).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 5 Training: Loss: 0.026286 Acc: 0.769720  Validation Loss: 0.021489 Acc: 0.815800                                                      \n",
      "Validation loss decreased (0.024412 --> 0.021489).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 6 Training: Loss: 0.024369 Acc: 0.788320  Validation Loss: 0.020668 Acc: 0.825200                                                      \n",
      "Validation loss decreased (0.021489 --> 0.020668).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 7 Training: Loss: 0.022953 Acc: 0.799400  Validation Loss: 0.018709 Acc: 0.841300                                                      \n",
      "Validation loss decreased (0.020668 --> 0.018709).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 8 Training: Loss: 0.021474 Acc: 0.816720  Validation Loss: 0.018156 Acc: 0.846700                                                      \n",
      "Validation loss decreased (0.018709 --> 0.018156).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 9 Training: Loss: 0.020352 Acc: 0.822560  Validation Loss: 0.017890 Acc: 0.846400                                                      \n",
      "Validation loss decreased (0.018156 --> 0.017890).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 10 Training: Loss: 0.019067 Acc: 0.835540  Validation Loss: 0.015247 Acc: 0.869000                                                      \n",
      "Validation loss decreased (0.017890 --> 0.015247).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 11 Training: Loss: 0.018103 Acc: 0.843700  Validation Loss: 0.015827 Acc: 0.861900                                                      \n",
      "Epoch: 12 Training: Loss: 0.017241 Acc: 0.848020  Validation Loss: 0.015246 Acc: 0.869600                                                      \n",
      "Validation loss decreased (0.015247 --> 0.015246).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 13 Training: Loss: 0.016447 Acc: 0.855940  Validation Loss: 0.014620 Acc: 0.877000                                                      \n",
      "Validation loss decreased (0.015246 --> 0.014620).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 14 Training: Loss: 0.015814 Acc: 0.862120  Validation Loss: 0.014201 Acc: 0.877400                                                      \n",
      "Validation loss decreased (0.014620 --> 0.014201).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 15 Training: Loss: 0.015183 Acc: 0.867920  Validation Loss: 0.013690 Acc: 0.883200                                                      \n",
      "Validation loss decreased (0.014201 --> 0.013690).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 16 Training: Loss: 0.014463 Acc: 0.874060  Validation Loss: 0.012798 Acc: 0.891400                                                      \n",
      "Validation loss decreased (0.013690 --> 0.012798).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 17 Training: Loss: 0.013971 Acc: 0.876740  Validation Loss: 0.013217 Acc: 0.889600                                                      \n",
      "Epoch: 18 Training: Loss: 0.013402 Acc: 0.883720  Validation Loss: 0.012709 Acc: 0.892900                                                      \n",
      "Validation loss decreased (0.012798 --> 0.012709).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 19 Training: Loss: 0.012741 Acc: 0.887980  Validation Loss: 0.013235 Acc: 0.889800                                                      \n",
      "Epoch: 20 Training: Loss: 0.012363 Acc: 0.890940  Validation Loss: 0.013338 Acc: 0.887000                                                      \n",
      "Epoch: 21 Training: Loss: 0.011813 Acc: 0.896040  Validation Loss: 0.013297 Acc: 0.888400                                                      \n",
      "Epoch: 22 Training: Loss: 0.011530 Acc: 0.900180  Validation Loss: 0.012516 Acc: 0.894600                                                      \n",
      "Validation loss decreased (0.012709 --> 0.012516).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 23 Training: Loss: 0.010961 Acc: 0.904240  Validation Loss: 0.012275 Acc: 0.898900                                                      \n",
      "Validation loss decreased (0.012516 --> 0.012275).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 24 Training: Loss: 0.010735 Acc: 0.906300  Validation Loss: 0.012174 Acc: 0.901300                                                      \n",
      "Validation loss decreased (0.012275 --> 0.012174).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 25 Training: Loss: 0.010282 Acc: 0.910340  Validation Loss: 0.012587 Acc: 0.894800                                                      \n",
      "Epoch: 26 Training: Loss: 0.010103 Acc: 0.911340  Validation Loss: 0.011399 Acc: 0.909600                                                      \n",
      "Validation loss decreased (0.012174 --> 0.011399).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 27 Training: Loss: 0.009522 Acc: 0.916900  Validation Loss: 0.011866 Acc: 0.907300                                                      \n",
      "Epoch: 28 Training: Loss: 0.009372 Acc: 0.917960  Validation Loss: 0.013365 Acc: 0.893300                                                      \n",
      "Epoch: 29 Training: Loss: 0.009138 Acc: 0.918180  Validation Loss: 0.011618 Acc: 0.906800                                                      \n",
      "Epoch: 30 Training: Loss: 0.008928 Acc: 0.921660  Validation Loss: 0.012133 Acc: 0.902400                                                      \n",
      "Epoch: 31 Training: Loss: 0.008596 Acc: 0.925080  Validation Loss: 0.011557 Acc: 0.907300                                                      \n",
      "Epoch: 32 Training: Loss: 0.008213 Acc: 0.928500  Validation Loss: 0.012509 Acc: 0.904400                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 33 Training: Loss: 0.008143 Acc: 0.928180  Validation Loss: 0.011834 Acc: 0.908300                                                      \n",
      "Epoch: 34 Training: Loss: 0.007780 Acc: 0.932060  Validation Loss: 0.011550 Acc: 0.908300                                                      \n",
      "Epoch: 35 Training: Loss: 0.007539 Acc: 0.934580  Validation Loss: 0.011471 Acc: 0.913300                                                      \n",
      "Epoch: 36 Training: Loss: 0.007312 Acc: 0.935140  Validation Loss: 0.011483 Acc: 0.913300                                                      \n",
      "Epoch: 37 Training: Loss: 0.007149 Acc: 0.937280  Validation Loss: 0.011511 Acc: 0.912900                                                      \n",
      "Epoch: 38 Training: Loss: 0.006852 Acc: 0.939280  Validation Loss: 0.012296 Acc: 0.906800                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 39 Training: Loss: 0.006801 Acc: 0.940180  Validation Loss: 0.011401 Acc: 0.913100                                                      \n",
      "Epoch: 40 Training: Loss: 0.006504 Acc: 0.942580  Validation Loss: 0.011254 Acc: 0.913300                                                      \n",
      "Validation loss decreased (0.011399 --> 0.011254).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 41 Training: Loss: 0.006428 Acc: 0.942960  Validation Loss: 0.012148 Acc: 0.911700                                                      \n",
      "Epoch: 42 Training: Loss: 0.006304 Acc: 0.945220  Validation Loss: 0.011597 Acc: 0.914100                                                      \n",
      "Epoch: 43 Training: Loss: 0.006039 Acc: 0.947120  Validation Loss: 0.010946 Acc: 0.918300                                                      \n",
      "Validation loss decreased (0.011254 --> 0.010946).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 44 Training: Loss: 0.005899 Acc: 0.947660  Validation Loss: 0.012818 Acc: 0.910900                                                      \n",
      "Epoch: 45 Training: Loss: 0.005717 Acc: 0.949880  Validation Loss: 0.011920 Acc: 0.914800                                                      \n",
      "Epoch: 46 Training: Loss: 0.005638 Acc: 0.949740  Validation Loss: 0.011236 Acc: 0.916500                                                      \n",
      "Epoch: 47 Training: Loss: 0.005516 Acc: 0.951340  Validation Loss: 0.011723 Acc: 0.914800                                                      \n",
      "Epoch: 48 Training: Loss: 0.005349 Acc: 0.952620  Validation Loss: 0.012415 Acc: 0.910900                                                      \n",
      "Epoch: 49 Training: Loss: 0.005397 Acc: 0.951940  Validation Loss: 0.011267 Acc: 0.918600                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 50 Training: Loss: 0.005041 Acc: 0.955540  Validation Loss: 0.013674 Acc: 0.908400                                                      \n",
      "Epoch: 51 Training: Loss: 0.005043 Acc: 0.955000  Validation Loss: 0.012185 Acc: 0.912500                                                      \n",
      "Epoch: 52 Training: Loss: 0.004851 Acc: 0.956900  Validation Loss: 0.011750 Acc: 0.917100                                                      \n",
      "Epoch: 53 Training: Loss: 0.004755 Acc: 0.957660  Validation Loss: 0.010859 Acc: 0.921100                                                      \n",
      "Validation loss decreased (0.010946 --> 0.010859).  Saving model to models_data/resnet18_cifar10\\model6\n",
      "Epoch: 54 Training: Loss: 0.004618 Acc: 0.958920  Validation Loss: 0.012547 Acc: 0.916600                                                      \n",
      "Epoch: 55 Training: Loss: 0.004604 Acc: 0.959640  Validation Loss: 0.011862 Acc: 0.913600                                                      \n",
      "Epoch: 56 Training: Loss: 0.004553 Acc: 0.958820  Validation Loss: 0.011510 Acc: 0.919300                                                      \n",
      "Epoch: 57 Training: Loss: 0.004469 Acc: 0.960300  Validation Loss: 0.011223 Acc: 0.921200                                                      \n",
      "Epoch: 58 Training: Loss: 0.004325 Acc: 0.960560  Validation Loss: 0.011710 Acc: 0.918400                                                      \n",
      "Epoch: 59 Training: Loss: 0.004112 Acc: 0.964040  Validation Loss: 0.012216 Acc: 0.914900                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Test Loss: 0.012216                                                                                                                        \n",
      "Accuracy: 0.914899999999995\n"
     ]
    }
   ],
   "source": [
    "# self.model = torchvision.models.resnet18(weights=None)\n",
    "# self.model.conv1 = Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "# self.model.maxpool = nn.Identity()\n",
    "# self.model.fc = Linear(512, self.num_classes, bias=True)\n",
    "# self.criterion: torch.nn.modules.loss.CrossEntropyLoss = nn.CrossEntropyLoss()\n",
    "# self.model.to(self.DEVICE)\n",
    "# self.optimizer: torch.optim.Adam = optim.Adam(self.model.parameters(), lr=1e-4)  # lr=1e-4\n",
    "# self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=100, gamma=0.85)\n",
    "\n",
    "model6 = ModelManager(10, load=False, dir_=NOTEBOOK_NAME, model_name='model6')\n",
    "print(model6.model)\n",
    "print(model6.optimizer)\n",
    "print(model6.scheduler.gamma, model6.scheduler.step)\n",
    "# lr*.1 in epoch: 16\n",
    "model6.train(loader_train, loader_test, loader_test, 60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "<torch.optim.lr_scheduler.StepLR object at 0x0000027E0AA10AF0>\n",
      "Epoch: 0 Training: Loss: 0.057672 Acc: 0.474480  Validation Loss: 0.042651 Acc: 0.622000                                                     \n",
      "Validation loss decreased (inf --> 0.042651).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 1 Training: Loss: 0.041217 Acc: 0.635760  Validation Loss: 0.034133 Acc: 0.705500                                                      \n",
      "Validation loss decreased (0.042651 --> 0.034133).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 2 Training: Loss: 0.033638 Acc: 0.707000  Validation Loss: 0.026327 Acc: 0.769600                                                      \n",
      "Validation loss decreased (0.034133 --> 0.026327).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 3 Training: Loss: 0.028995 Acc: 0.746040  Validation Loss: 0.022376 Acc: 0.809200                                                      \n",
      "Validation loss decreased (0.026327 --> 0.022376).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 4 Training: Loss: 0.025739 Acc: 0.776320  Validation Loss: 0.019953 Acc: 0.829700                                                      \n",
      "Validation loss decreased (0.022376 --> 0.019953).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 5 Training: Loss: 0.023327 Acc: 0.797980  Validation Loss: 0.018423 Acc: 0.839500                                                      \n",
      "Validation loss decreased (0.019953 --> 0.018423).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 6 Training: Loss: 0.021303 Acc: 0.817560  Validation Loss: 0.018156 Acc: 0.846000                                                      \n",
      "Validation loss decreased (0.018423 --> 0.018156).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 7 Training: Loss: 0.019399 Acc: 0.831620  Validation Loss: 0.016870 Acc: 0.856700                                                      \n",
      "Validation loss decreased (0.018156 --> 0.016870).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 8 Training: Loss: 0.017926 Acc: 0.845740  Validation Loss: 0.016770 Acc: 0.863900                                                      \n",
      "Validation loss decreased (0.016870 --> 0.016770).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 9 Training: Loss: 0.016810 Acc: 0.852920  Validation Loss: 0.015011 Acc: 0.871800                                                      \n",
      "Validation loss decreased (0.016770 --> 0.015011).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 10 Training: Loss: 0.015634 Acc: 0.865320  Validation Loss: 0.013892 Acc: 0.883600                                                      \n",
      "Validation loss decreased (0.015011 --> 0.013892).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 11 Training: Loss: 0.014653 Acc: 0.872580  Validation Loss: 0.013315 Acc: 0.885600                                                      \n",
      "Validation loss decreased (0.013892 --> 0.013315).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 12 Training: Loss: 0.013956 Acc: 0.879020  Validation Loss: 0.012233 Acc: 0.901800                                                      \n",
      "Validation loss decreased (0.013315 --> 0.012233).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 13 Training: Loss: 0.012993 Acc: 0.887380  Validation Loss: 0.012342 Acc: 0.895900                                                      \n",
      "Epoch: 14 Training: Loss: 0.012383 Acc: 0.890680  Validation Loss: 0.011992 Acc: 0.903400                                                      \n",
      "Validation loss decreased (0.012233 --> 0.011992).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 15 Training: Loss: 0.011648 Acc: 0.897860  Validation Loss: 0.011104 Acc: 0.906500                                                      \n",
      "Validation loss decreased (0.011992 --> 0.011104).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 16 Training: Loss: 0.011195 Acc: 0.901180  Validation Loss: 0.011693 Acc: 0.904800                                                      \n",
      "Epoch: 17 Training: Loss: 0.010805 Acc: 0.906200  Validation Loss: 0.011956 Acc: 0.901100                                                      \n",
      "Epoch: 18 Training: Loss: 0.010085 Acc: 0.912640  Validation Loss: 0.011112 Acc: 0.906700                                                      \n",
      "Epoch: 19 Training: Loss: 0.009617 Acc: 0.915160  Validation Loss: 0.011375 Acc: 0.906700                                                      \n",
      "Epoch: 20 Training: Loss: 0.009245 Acc: 0.918100  Validation Loss: 0.010663 Acc: 0.908400                                                      \n",
      "Validation loss decreased (0.011104 --> 0.010663).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 21 Training: Loss: 0.008849 Acc: 0.921680  Validation Loss: 0.011138 Acc: 0.909300                                                      \n",
      "Epoch: 22 Training: Loss: 0.008655 Acc: 0.924000  Validation Loss: 0.011140 Acc: 0.911000                                                      \n",
      "Epoch: 23 Training: Loss: 0.008182 Acc: 0.927000  Validation Loss: 0.010997 Acc: 0.911500                                                      \n",
      "Epoch: 24 Training: Loss: 0.007753 Acc: 0.931400  Validation Loss: 0.011097 Acc: 0.908600                                                      \n",
      "Epoch: 25 Training: Loss: 0.007462 Acc: 0.933640  Validation Loss: 0.010913 Acc: 0.913900                                                      \n",
      "Epoch: 26 Training: Loss: 0.007202 Acc: 0.937300  Validation Loss: 0.010405 Acc: 0.919000                                                      \n",
      "Validation loss decreased (0.010663 --> 0.010405).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 27 Training: Loss: 0.006984 Acc: 0.938140  Validation Loss: 0.010664 Acc: 0.919900                                                      \n",
      "Epoch: 28 Training: Loss: 0.006746 Acc: 0.940100  Validation Loss: 0.011038 Acc: 0.916400                                                      \n",
      "Epoch: 29 Training: Loss: 0.006518 Acc: 0.942820  Validation Loss: 0.010705 Acc: 0.916400                                                      \n",
      "Epoch: 30 Training: Loss: 0.006283 Acc: 0.945340  Validation Loss: 0.010088 Acc: 0.922000                                                      \n",
      "Validation loss decreased (0.010405 --> 0.010088).  Saving model to models_data/resnet18_cifar10\\model7\n",
      "Epoch: 31 Training: Loss: 0.006037 Acc: 0.946020  Validation Loss: 0.011020 Acc: 0.916800                                                      \n",
      "Epoch: 32 Training: Loss: 0.005814 Acc: 0.949540  Validation Loss: 0.010942 Acc: 0.921800                                                      \n",
      "Epoch: 33 Training: Loss: 0.005790 Acc: 0.949680  Validation Loss: 0.010571 Acc: 0.920900                                                      \n",
      "Epoch: 34 Training: Loss: 0.005565 Acc: 0.950880  Validation Loss: 0.010913 Acc: 0.917300                                                      \n",
      "Epoch: 35 Training: Loss: 0.005326 Acc: 0.953580  Validation Loss: 0.011551 Acc: 0.917700                                                      \n",
      "Epoch: 36 Training: Loss: 0.005121 Acc: 0.954800  Validation Loss: 0.010269 Acc: 0.925500                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 37 Training: Loss: 0.005089 Acc: 0.955140  Validation Loss: 0.011664 Acc: 0.921700                                                      \n",
      "Epoch: 38 Training: Loss: 0.005008 Acc: 0.955920  Validation Loss: 0.011213 Acc: 0.921000                                                      \n",
      "Epoch: 39 Training: Loss: 0.004761 Acc: 0.957780  Validation Loss: 0.011321 Acc: 0.922300                                                      \n",
      "Epoch: 40 Training: Loss: 0.004752 Acc: 0.957780  Validation Loss: 0.012726 Acc: 0.911900                                                      \n",
      "Epoch: 41 Training: Loss: 0.004517 Acc: 0.960200  Validation Loss: 0.011577 Acc: 0.919400                                                      \n",
      "Epoch: 42 Training: Loss: 0.004467 Acc: 0.961500  Validation Loss: 0.012559 Acc: 0.917100                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 43 Training: Loss: 0.004299 Acc: 0.962460  Validation Loss: 0.011185 Acc: 0.928100                                                      \n",
      "Epoch: 44 Training: Loss: 0.004157 Acc: 0.963740  Validation Loss: 0.011387 Acc: 0.923500                                                      \n",
      "Epoch: 45 Training: Loss: 0.004231 Acc: 0.963540  Validation Loss: 0.012031 Acc: 0.920300                                                      \n",
      "Epoch: 46 Training: Loss: 0.003951 Acc: 0.966140  Validation Loss: 0.011298 Acc: 0.925300                                                      \n",
      "Epoch: 47 Training: Loss: 0.004098 Acc: 0.965000  Validation Loss: 0.011302 Acc: 0.923900                                                      \n",
      "Epoch: 48 Training: Loss: 0.003852 Acc: 0.965800  Validation Loss: 0.011244 Acc: 0.923500                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 49 Training: Loss: 0.003958 Acc: 0.966260  Validation Loss: 0.011892 Acc: 0.923700                                                      \n",
      "Epoch: 50 Training: Loss: 0.003685 Acc: 0.967960  Validation Loss: 0.012355 Acc: 0.924300                                                      \n",
      "Epoch: 51 Training: Loss: 0.003798 Acc: 0.966400  Validation Loss: 0.010974 Acc: 0.929200                                                      \n",
      "Epoch: 52 Training: Loss: 0.003636 Acc: 0.967700  Validation Loss: 0.011807 Acc: 0.925900                                                      \n",
      "Epoch: 53 Training: Loss: 0.003557 Acc: 0.968960  Validation Loss: 0.011998 Acc: 0.923900                                                      \n",
      "Epoch: 54 Training: Loss: 0.003511 Acc: 0.970300  Validation Loss: 0.011799 Acc: 0.925200                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 55 Training: Loss: 0.003390 Acc: 0.970180  Validation Loss: 0.011581 Acc: 0.929100                                                      \n",
      "Epoch: 56 Training: Loss: 0.003305 Acc: 0.971280  Validation Loss: 0.012985 Acc: 0.918500                                                      \n",
      "Epoch: 57 Training: Loss: 0.003177 Acc: 0.973140  Validation Loss: 0.012038 Acc: 0.924100                                                      \n",
      "Epoch: 58 Training: Loss: 0.003113 Acc: 0.973460  Validation Loss: 0.013064 Acc: 0.927100                                                      \n",
      "Epoch: 59 Training: Loss: 0.003194 Acc: 0.971760  Validation Loss: 0.011388 Acc: 0.929200                                                      \n",
      "Test Loss: 0.011388                                                                                                                        \n",
      "Accuracy: 0.9291999999999946\n"
     ]
    }
   ],
   "source": [
    "# self.model = torchvision.models.resnet18(weights=None)\n",
    "# self.model.conv1 = Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "# self.model.maxpool = nn.Identity()\n",
    "# self.model.fc = Linear(512, self.num_classes, bias=True)\n",
    "# self.optimizer: torch.optim.Adam = optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "#  self.scheduler: optim.lr_scheduler.StepLR(self.optimizer, step_size=100, gamma=0.85)\n",
    "model7 = ModelManager(NUM_CLASSES, load=False, dir_=NOTEBOOK_NAME, model_name='model7')\n",
    "print(model7.model)\n",
    "print(model7.optimizer)\n",
    "print(model7.scheduler)\n",
    "model7.train(loader_train, loader_test, loader_test, EPOCHS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "<torch.optim.lr_scheduler.StepLR object at 0x0000021A990A5360>\n",
      "Epoch: 0 Training: Loss: 0.062031 Acc: 0.427840  Validation Loss: 0.045554 Acc: 0.582500                                                     \n",
      "Validation loss decreased (inf --> 0.045554).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 1 Training: Loss: 0.045282 Acc: 0.595600  Validation Loss: 0.036624 Acc: 0.674700                                                      \n",
      "Validation loss decreased (0.045554 --> 0.036624).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 2 Training: Loss: 0.036962 Acc: 0.672760  Validation Loss: 0.028301 Acc: 0.753100                                                      \n",
      "Validation loss decreased (0.036624 --> 0.028301).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 3 Training: Loss: 0.031351 Acc: 0.724600  Validation Loss: 0.026614 Acc: 0.772100                                                      \n",
      "Validation loss decreased (0.028301 --> 0.026614).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 4 Training: Loss: 0.027826 Acc: 0.759760  Validation Loss: 0.022425 Acc: 0.805800                                                      \n",
      "Validation loss decreased (0.026614 --> 0.022425).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 5 Training: Loss: 0.024878 Acc: 0.783980  Validation Loss: 0.021221 Acc: 0.815600                                                      \n",
      "Validation loss decreased (0.022425 --> 0.021221).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 6 Training: Loss: 0.022733 Acc: 0.802240  Validation Loss: 0.017982 Acc: 0.848400                                                      \n",
      "Validation loss decreased (0.021221 --> 0.017982).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 7 Training: Loss: 0.021028 Acc: 0.818060  Validation Loss: 0.018012 Acc: 0.846500                                                      \n",
      "Epoch: 8 Training: Loss: 0.019429 Acc: 0.832500  Validation Loss: 0.016744 Acc: 0.856100                                                      \n",
      "Validation loss decreased (0.017982 --> 0.016744).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 9 Training: Loss: 0.018313 Acc: 0.842720  Validation Loss: 0.017178 Acc: 0.853800                                                      \n",
      "Epoch: 10 Training: Loss: 0.016922 Acc: 0.853160  Validation Loss: 0.013822 Acc: 0.881100                                                      \n",
      "Validation loss decreased (0.016744 --> 0.013822).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 11 Training: Loss: 0.016052 Acc: 0.859460  Validation Loss: 0.013660 Acc: 0.884400                                                      \n",
      "Validation loss decreased (0.013822 --> 0.013660).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 12 Training: Loss: 0.015241 Acc: 0.869240  Validation Loss: 0.013098 Acc: 0.889200                                                      \n",
      "Validation loss decreased (0.013660 --> 0.013098).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 13 Training: Loss: 0.014337 Acc: 0.876680  Validation Loss: 0.012290 Acc: 0.895900                                                      \n",
      "Validation loss decreased (0.013098 --> 0.012290).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 14 Training: Loss: 0.013546 Acc: 0.881340  Validation Loss: 0.012513 Acc: 0.896600                                                      \n",
      "Epoch: 15 Training: Loss: 0.012909 Acc: 0.888920  Validation Loss: 0.013331 Acc: 0.890400                                                      \n",
      "Epoch: 16 Training: Loss: 0.012292 Acc: 0.891680  Validation Loss: 0.013068 Acc: 0.894100                                                      \n",
      "Epoch: 17 Training: Loss: 0.011848 Acc: 0.896420  Validation Loss: 0.012182 Acc: 0.898300                                                      \n",
      "Validation loss decreased (0.012290 --> 0.012182).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 18 Training: Loss: 0.011075 Acc: 0.902720  Validation Loss: 0.011890 Acc: 0.901800                                                      \n",
      "Validation loss decreased (0.012182 --> 0.011890).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 19 Training: Loss: 0.010694 Acc: 0.906780  Validation Loss: 0.012323 Acc: 0.896700                                                      \n",
      "Epoch: 20 Training: Loss: 0.010128 Acc: 0.911180  Validation Loss: 0.010935 Acc: 0.910900                                                      \n",
      "Validation loss decreased (0.011890 --> 0.010935).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 21 Training: Loss: 0.009849 Acc: 0.914460  Validation Loss: 0.010677 Acc: 0.911900                                                      \n",
      "Validation loss decreased (0.010935 --> 0.010677).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 22 Training: Loss: 0.009358 Acc: 0.918180  Validation Loss: 0.010768 Acc: 0.912300                                                      \n",
      "Epoch: 23 Training: Loss: 0.009007 Acc: 0.920560  Validation Loss: 0.011231 Acc: 0.912700                                                      \n",
      "Epoch: 24 Training: Loss: 0.008621 Acc: 0.924800  Validation Loss: 0.011208 Acc: 0.911200                                                      \n",
      "Epoch: 25 Training: Loss: 0.008336 Acc: 0.927640  Validation Loss: 0.011089 Acc: 0.913200                                                      \n",
      "Epoch: 26 Training: Loss: 0.007874 Acc: 0.930520  Validation Loss: 0.010552 Acc: 0.913600                                                      \n",
      "Validation loss decreased (0.010677 --> 0.010552).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 27 Training: Loss: 0.007656 Acc: 0.932140  Validation Loss: 0.010565 Acc: 0.916500                                                      \n",
      "Epoch: 28 Training: Loss: 0.007531 Acc: 0.933520  Validation Loss: 0.011194 Acc: 0.913300                                                      \n",
      "Epoch: 29 Training: Loss: 0.007087 Acc: 0.937580  Validation Loss: 0.011034 Acc: 0.915800                                                      \n",
      "Epoch: 30 Training: Loss: 0.006836 Acc: 0.941240  Validation Loss: 0.010565 Acc: 0.920400                                                      \n",
      "Epoch: 31 Training: Loss: 0.006695 Acc: 0.941200  Validation Loss: 0.010591 Acc: 0.920500                                                      \n",
      "Epoch: 32 Training: Loss: 0.006415 Acc: 0.943420  Validation Loss: 0.010251 Acc: 0.923800                                                      \n",
      "Validation loss decreased (0.010552 --> 0.010251).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 33 Training: Loss: 0.006217 Acc: 0.945040  Validation Loss: 0.011657 Acc: 0.911300                                                      \n",
      "Epoch: 34 Training: Loss: 0.006049 Acc: 0.947040  Validation Loss: 0.012405 Acc: 0.914400                                                      \n",
      "Epoch: 35 Training: Loss: 0.005878 Acc: 0.947700  Validation Loss: 0.010927 Acc: 0.916700                                                      \n",
      "Epoch: 36 Training: Loss: 0.005671 Acc: 0.949700  Validation Loss: 0.011256 Acc: 0.918400                                                      \n",
      "Epoch: 37 Training: Loss: 0.005602 Acc: 0.950160  Validation Loss: 0.010642 Acc: 0.919700                                                      \n",
      "Epoch: 38 Training: Loss: 0.005154 Acc: 0.954860  Validation Loss: 0.011142 Acc: 0.925300                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 39 Training: Loss: 0.005281 Acc: 0.953480  Validation Loss: 0.010762 Acc: 0.921400                                                      \n",
      "Epoch: 40 Training: Loss: 0.005011 Acc: 0.955500  Validation Loss: 0.010859 Acc: 0.920800                                                      \n",
      "Epoch: 41 Training: Loss: 0.005046 Acc: 0.955480  Validation Loss: 0.011791 Acc: 0.916600                                                      \n",
      "Epoch: 42 Training: Loss: 0.004847 Acc: 0.957740  Validation Loss: 0.011121 Acc: 0.920500                                                      \n",
      "Epoch: 43 Training: Loss: 0.004649 Acc: 0.957880  Validation Loss: 0.010364 Acc: 0.926400                                                      \n",
      "Epoch: 44 Training: Loss: 0.004692 Acc: 0.959160  Validation Loss: 0.010631 Acc: 0.925100                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 45 Training: Loss: 0.004537 Acc: 0.960020  Validation Loss: 0.011272 Acc: 0.921600                                                      \n",
      "Epoch: 46 Training: Loss: 0.004350 Acc: 0.961920  Validation Loss: 0.010316 Acc: 0.926800                                                      \n",
      "Epoch: 47 Training: Loss: 0.004361 Acc: 0.962740  Validation Loss: 0.010145 Acc: 0.931700                                                      \n",
      "Validation loss decreased (0.010251 --> 0.010145).  Saving model to models_data/resnet18_cifar10\\model8\n",
      "Epoch: 48 Training: Loss: 0.004174 Acc: 0.964040  Validation Loss: 0.011634 Acc: 0.920500                                                      \n",
      "Epoch: 49 Training: Loss: 0.003976 Acc: 0.964480  Validation Loss: 0.011216 Acc: 0.923800                                                      \n",
      "Epoch: 50 Training: Loss: 0.004025 Acc: 0.964980  Validation Loss: 0.010847 Acc: 0.923100                                                      \n",
      "Epoch: 51 Training: Loss: 0.003847 Acc: 0.966040  Validation Loss: 0.011538 Acc: 0.924600                                                      \n",
      "Epoch: 52 Training: Loss: 0.003879 Acc: 0.966060  Validation Loss: 0.010952 Acc: 0.928100                                                      \n",
      "Epoch: 53 Training: Loss: 0.003764 Acc: 0.966720  Validation Loss: 0.011042 Acc: 0.925700                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 54 Training: Loss: 0.003700 Acc: 0.967700  Validation Loss: 0.010764 Acc: 0.927600                                                      \n",
      "Epoch: 55 Training: Loss: 0.003499 Acc: 0.969060  Validation Loss: 0.011664 Acc: 0.924400                                                      \n",
      "Epoch: 56 Training: Loss: 0.003590 Acc: 0.968920  Validation Loss: 0.011357 Acc: 0.925800                                                      \n",
      "Epoch: 57 Training: Loss: 0.003543 Acc: 0.969200  Validation Loss: 0.011120 Acc: 0.927300                                                      \n",
      "Epoch: 58 Training: Loss: 0.003479 Acc: 0.969320  Validation Loss: 0.011659 Acc: 0.926900                                                      \n",
      "Epoch: 59 Training: Loss: 0.003340 Acc: 0.970380  Validation Loss: 0.011213 Acc: 0.928900                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Test Loss: 0.011213                                                                                                                        \n",
      "Accuracy: 0.9288999999999946\n"
     ]
    }
   ],
   "source": [
    "# extra fc\n",
    "\n",
    "# self.model = torchvision.models.resnet18(weights=None)\n",
    "# self.model.conv1 = Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "# self.model.maxpool = nn.Identity()\n",
    "# self.model.fc = Sequential(Linear(512, 128, bias=True), Linear(128, self.num_classes, bias=True))\n",
    "# self.optimizer: torch.optim.Adam = optim.Adam(self.model.parameters(), lr=1e-3)  # lr=1e-4\n",
    "# self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=100, gamma=0.85)\n",
    "\n",
    "model8 = ModelManager(NUM_CLASSES, load=False, dir_=NOTEBOOK_NAME, model_name='model8')\n",
    "print(model8.model)\n",
    "print(model8.optimizer)\n",
    "print(model8.scheduler)\n",
    "model8.train(loader_train, loader_test, loader_test, EPOCHS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "<torch.optim.lr_scheduler.StepLR object at 0x000002B9AE3CDC00>\n",
      "Epoch: 60 Training: Loss: 0.008002 Acc: 0.929000  Validation Loss: 0.011061 Acc: 0.913500                                                      \n",
      "Epoch: 61 Training: Loss: 0.007976 Acc: 0.929460  Validation Loss: 0.009991 Acc: 0.923500                                                      \n",
      "Epoch: 62 Training: Loss: 0.007904 Acc: 0.931240  Validation Loss: 0.010522 Acc: 0.918900                                                      \n",
      "Epoch: 63 Training: Loss: 0.007729 Acc: 0.933140  Validation Loss: 0.011308 Acc: 0.912700                                                      \n",
      "Epoch: 64 Training: Loss: 0.007833 Acc: 0.930840  Validation Loss: 0.010880 Acc: 0.914000                                                      \n",
      "Epoch: 65 Training: Loss: 0.007642 Acc: 0.934380  Validation Loss: 0.011386 Acc: 0.912300                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 66 Training: Loss: 0.007539 Acc: 0.934160  Validation Loss: 0.010372 Acc: 0.922200                                                      \n",
      "Epoch: 67 Training: Loss: 0.007419 Acc: 0.934780  Validation Loss: 0.010605 Acc: 0.914100                                                      \n",
      "Epoch: 68 Training: Loss: 0.007598 Acc: 0.932680  Validation Loss: 0.010430 Acc: 0.916400                                                      \n",
      "Epoch: 69 Training: Loss: 0.007349 Acc: 0.936060  Validation Loss: 0.010770 Acc: 0.915100                                                      \n",
      "Test Loss: 0.010770                                                                                                                        \n",
      "Accuracy: 0.9150999999999948\n"
     ]
    }
   ],
   "source": [
    "# self.model = torchvision.models.resnet18(weights=None)\n",
    "# self.model.conv1 = Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "# self.model.maxpool = nn.Identity()\n",
    "# self.model.fc = Sequential(Linear(512, 128, bias=True), Linear(128, self.num_classes, bias=True))\n",
    "# self.optimizer: torch.optim.Adam =  optim.Adam(self.model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "# self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=100, gamma=0.85)\n",
    "\n",
    "model9 = ModelManager(NUM_CLASSES, load=True, dir_=NOTEBOOK_NAME, model_name='model9')\n",
    "print(model9.model)\n",
    "print(model9.optimizer)\n",
    "print(model9.scheduler)\n",
    "model9.train(loader_train, loader_test, loader_test, 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x0000024AD2252260>\n",
      "Epoch: 0 Training: Loss: 0.058102 Acc: 0.470560  Validation Loss: 0.045886 Acc: 0.593700                                                     \n",
      "Validation loss decreased (inf --> 0.045886).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 1 Training: Loss: 0.041783 Acc: 0.630280  Validation Loss: 0.033557 Acc: 0.710300                                                      \n",
      "Validation loss decreased (0.045886 --> 0.033557).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 2 Training: Loss: 0.033978 Acc: 0.703820  Validation Loss: 0.026220 Acc: 0.776700                                                      \n",
      "Validation loss decreased (0.033557 --> 0.026220).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 3 Training: Loss: 0.029318 Acc: 0.745780  Validation Loss: 0.024076 Acc: 0.796500                                                      \n",
      "Validation loss decreased (0.026220 --> 0.024076).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 4 Training: Loss: 0.025884 Acc: 0.776340  Validation Loss: 0.020367 Acc: 0.825800                                                      \n",
      "Validation loss decreased (0.024076 --> 0.020367).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 5 Training: Loss: 0.023132 Acc: 0.799660  Validation Loss: 0.019645 Acc: 0.829600                                                      \n",
      "Validation loss decreased (0.020367 --> 0.019645).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 6 Training: Loss: 0.021137 Acc: 0.817300  Validation Loss: 0.017432 Acc: 0.850400                                                      \n",
      "Validation loss decreased (0.019645 --> 0.017432).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 7 Training: Loss: 0.019413 Acc: 0.831920  Validation Loss: 0.016664 Acc: 0.860900                                                      \n",
      "Validation loss decreased (0.017432 --> 0.016664).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 8 Training: Loss: 0.017856 Acc: 0.845200  Validation Loss: 0.014405 Acc: 0.875900                                                      \n",
      "Validation loss decreased (0.016664 --> 0.014405).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 9 Training: Loss: 0.016612 Acc: 0.856220  Validation Loss: 0.014000 Acc: 0.881600                                                      \n",
      "Validation loss decreased (0.014405 --> 0.014000).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 10 Training: Loss: 0.015600 Acc: 0.863440  Validation Loss: 0.013801 Acc: 0.884100                                                      \n",
      "Validation loss decreased (0.014000 --> 0.013801).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 11 Training: Loss: 0.014832 Acc: 0.872760  Validation Loss: 0.014243 Acc: 0.877600                                                      \n",
      "Epoch: 12 Training: Loss: 0.013838 Acc: 0.879820  Validation Loss: 0.012512 Acc: 0.895200                                                      \n",
      "Validation loss decreased (0.013801 --> 0.012512).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 13 Training: Loss: 0.012996 Acc: 0.886420  Validation Loss: 0.013178 Acc: 0.890400                                                      \n",
      "Epoch: 14 Training: Loss: 0.012348 Acc: 0.893440  Validation Loss: 0.012849 Acc: 0.893400                                                      \n",
      "Epoch: 15 Training: Loss: 0.011715 Acc: 0.897060  Validation Loss: 0.011702 Acc: 0.899200                                                      \n",
      "Validation loss decreased (0.012512 --> 0.011702).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 16 Training: Loss: 0.011237 Acc: 0.903120  Validation Loss: 0.011588 Acc: 0.901600                                                      \n",
      "Validation loss decreased (0.011702 --> 0.011588).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 17 Training: Loss: 0.010452 Acc: 0.908740  Validation Loss: 0.011352 Acc: 0.900800                                                      \n",
      "Validation loss decreased (0.011588 --> 0.011352).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 18 Training: Loss: 0.010059 Acc: 0.910220  Validation Loss: 0.012000 Acc: 0.898800                                                      \n",
      "Epoch: 19 Training: Loss: 0.009794 Acc: 0.914980  Validation Loss: 0.010533 Acc: 0.908700                                                      \n",
      "Validation loss decreased (0.011352 --> 0.010533).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 20 Training: Loss: 0.009221 Acc: 0.919680  Validation Loss: 0.011275 Acc: 0.909800                                                      \n",
      "Epoch: 21 Training: Loss: 0.009027 Acc: 0.921500  Validation Loss: 0.010696 Acc: 0.911900                                                      \n",
      "Epoch 00023: reducing learning rate of group 0 to 1.0000e-04.                                                                                  \n",
      "Epoch: 22 Training: Loss: 0.008358 Acc: 0.925700  Validation Loss: 0.010913 Acc: 0.914200\n",
      "Epoch: 23 Training: Loss: 0.006045 Acc: 0.946440  Validation Loss: 0.008738 Acc: 0.929500                                                      \n",
      "Validation loss decreased (0.010533 --> 0.008738).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 24 Training: Loss: 0.005336 Acc: 0.952180  Validation Loss: 0.008531 Acc: 0.931300                                                      \n",
      "Validation loss decreased (0.008738 --> 0.008531).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 25 Training: Loss: 0.004786 Acc: 0.958420  Validation Loss: 0.008730 Acc: 0.932700                                                      \n",
      "Epoch: 26 Training: Loss: 0.004644 Acc: 0.959000  Validation Loss: 0.008816 Acc: 0.930600                                                      \n",
      "Epoch 00028: reducing learning rate of group 0 to 1.0000e-05.                                                                                  \n",
      "Epoch: 27 Training: Loss: 0.004420 Acc: 0.961240  Validation Loss: 0.008700 Acc: 0.932200\n",
      "Epoch: 28 Training: Loss: 0.004207 Acc: 0.962880  Validation Loss: 0.008771 Acc: 0.932400                                                      \n",
      "Epoch: 29 Training: Loss: 0.004095 Acc: 0.964500  Validation Loss: 0.008620 Acc: 0.933600                                                      \n",
      "Epoch 00031: reducing learning rate of group 0 to 1.0000e-06.                                                                                  \n",
      "Epoch: 30 Training: Loss: 0.004008 Acc: 0.965300  Validation Loss: 0.008658 Acc: 0.933100\n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 31 Training: Loss: 0.004067 Acc: 0.964620  Validation Loss: 0.008559 Acc: 0.933500                                                      \n",
      "Epoch: 32 Training: Loss: 0.003912 Acc: 0.965520  Validation Loss: 0.008539 Acc: 0.933000                                                      \n",
      "Epoch 00034: reducing learning rate of group 0 to 1.0000e-07.                                                                                  \n",
      "Epoch: 33 Training: Loss: 0.004060 Acc: 0.964080  Validation Loss: 0.008645 Acc: 0.933300\n",
      "Epoch: 34 Training: Loss: 0.004062 Acc: 0.965120  Validation Loss: 0.008631 Acc: 0.933000                                                      \n",
      "Epoch: 35 Training: Loss: 0.004040 Acc: 0.964660  Validation Loss: 0.008614 Acc: 0.934300                                                      \n",
      "Epoch 00037: reducing learning rate of group 0 to 1.0000e-08.                                                                                  \n",
      "Epoch: 36 Training: Loss: 0.004121 Acc: 0.964580  Validation Loss: 0.008554 Acc: 0.934100\n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 37 Training: Loss: 0.003923 Acc: 0.965600  Validation Loss: 0.008627 Acc: 0.933500                                                      \n",
      "Epoch: 38 Training: Loss: 0.003965 Acc: 0.965960  Validation Loss: 0.008548 Acc: 0.934200                                                      \n",
      "Epoch: 39 Training: Loss: 0.004045 Acc: 0.965220  Validation Loss: 0.008611 Acc: 0.933400                                                      \n",
      "Epoch: 40 Training: Loss: 0.004004 Acc: 0.966020  Validation Loss: 0.008642 Acc: 0.933200                                                      \n",
      "Epoch: 41 Training: Loss: 0.004086 Acc: 0.963600  Validation Loss: 0.008571 Acc: 0.932800                                                      \n",
      "Epoch: 42 Training: Loss: 0.004057 Acc: 0.965380  Validation Loss: 0.008623 Acc: 0.933700                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 43 Training: Loss: 0.003972 Acc: 0.965020  Validation Loss: 0.008594 Acc: 0.932700                                                      \n",
      "Epoch: 44 Training: Loss: 0.003940 Acc: 0.965820  Validation Loss: 0.008645 Acc: 0.932900                                                      \n",
      "Epoch: 45 Training: Loss: 0.003978 Acc: 0.965340  Validation Loss: 0.008607 Acc: 0.933900                                                      \n",
      "Epoch: 46 Training: Loss: 0.004015 Acc: 0.965060  Validation Loss: 0.008640 Acc: 0.933200                                                      \n",
      "Epoch: 47 Training: Loss: 0.004060 Acc: 0.963960  Validation Loss: 0.008694 Acc: 0.933500                                                      \n",
      "Epoch: 48 Training: Loss: 0.004042 Acc: 0.965000  Validation Loss: 0.008605 Acc: 0.933400                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 49 Training: Loss: 0.004082 Acc: 0.964540  Validation Loss: 0.008551 Acc: 0.933300                                                      \n",
      "Epoch: 50 Training: Loss: 0.004028 Acc: 0.965040  Validation Loss: 0.008575 Acc: 0.933300                                                      \n",
      "Epoch: 51 Training: Loss: 0.003986 Acc: 0.965040  Validation Loss: 0.008601 Acc: 0.934000                                                      \n",
      "Epoch: 52 Training: Loss: 0.004046 Acc: 0.963640  Validation Loss: 0.008659 Acc: 0.933100                                                      \n",
      "Epoch: 53 Training: Loss: 0.004011 Acc: 0.965440  Validation Loss: 0.008618 Acc: 0.933500                                                      \n",
      "Epoch: 54 Training: Loss: 0.003944 Acc: 0.965460  Validation Loss: 0.008653 Acc: 0.933000                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 55 Training: Loss: 0.003950 Acc: 0.966140  Validation Loss: 0.008566 Acc: 0.932800                                                      \n",
      "Epoch: 56 Training: Loss: 0.004064 Acc: 0.963940  Validation Loss: 0.008672 Acc: 0.933900                                                      \n",
      "Epoch: 57 Training: Loss: 0.004054 Acc: 0.965540  Validation Loss: 0.008731 Acc: 0.932900                                                      \n",
      "Epoch: 58 Training: Loss: 0.004041 Acc: 0.965180  Validation Loss: 0.008707 Acc: 0.933400                                                      \n",
      "Epoch: 59 Training: Loss: 0.004011 Acc: 0.965500  Validation Loss: 0.008646 Acc: 0.933100                                                      \n",
      "Epoch: 60 Training: Loss: 0.003969 Acc: 0.965200  Validation Loss: 0.008628 Acc: 0.933200                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 61 Training: Loss: 0.004033 Acc: 0.964820  Validation Loss: 0.008655 Acc: 0.934800                                                      \n",
      "Epoch: 62 Training: Loss: 0.004002 Acc: 0.964820  Validation Loss: 0.008663 Acc: 0.934600                                                      \n",
      "Epoch: 63 Training: Loss: 0.004044 Acc: 0.964120  Validation Loss: 0.008698 Acc: 0.932900                                                      \n",
      "Epoch: 64 Training: Loss: 0.004042 Acc: 0.964980  Validation Loss: 0.008623 Acc: 0.933100                                                      \n",
      "Epoch: 65 Training: Loss: 0.004019 Acc: 0.965080  Validation Loss: 0.008537 Acc: 0.933000                                                      \n",
      "Epoch: 66 Training: Loss: 0.004008 Acc: 0.964780  Validation Loss: 0.008630 Acc: 0.932900                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 67 Training: Loss: 0.004001 Acc: 0.965620  Validation Loss: 0.008649 Acc: 0.933800                                                      \n",
      "Epoch: 68 Training: Loss: 0.004037 Acc: 0.964520  Validation Loss: 0.008597 Acc: 0.933100                                                      \n",
      "Epoch: 69 Training: Loss: 0.003956 Acc: 0.965460  Validation Loss: 0.008601 Acc: 0.933800                                                      \n",
      "Epoch: 70 Training: Loss: 0.003961 Acc: 0.965860  Validation Loss: 0.008639 Acc: 0.933300                                                      \n",
      "Epoch: 71 Training: Loss: 0.003997 Acc: 0.964160  Validation Loss: 0.008542 Acc: 0.934200                                                      \n",
      "Epoch: 72 Training: Loss: 0.004140 Acc: 0.964320  Validation Loss: 0.008597 Acc: 0.933900                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 73 Training: Loss: 0.004050 Acc: 0.963660  Validation Loss: 0.008559 Acc: 0.934200                                                      \n",
      "Epoch: 74 Training: Loss: 0.004003 Acc: 0.965020  Validation Loss: 0.008649 Acc: 0.933800                                                      \n",
      "Epoch: 75 Training: Loss: 0.004052 Acc: 0.963740  Validation Loss: 0.008598 Acc: 0.933800                                                      \n",
      "Epoch: 76 Training: Loss: 0.004048 Acc: 0.965180  Validation Loss: 0.008689 Acc: 0.934000                                                      \n",
      "Epoch: 77 Training: Loss: 0.003989 Acc: 0.965460  Validation Loss: 0.008624 Acc: 0.933700                                                      \n",
      "Epoch: 78 Training: Loss: 0.003994 Acc: 0.965280  Validation Loss: 0.008504 Acc: 0.932700                                                      \n",
      "Validation loss decreased (0.008531 --> 0.008504).  Saving model to models_data/resnet18_cifar10\\modelA\n",
      "Epoch: 79 Training: Loss: 0.003980 Acc: 0.964980  Validation Loss: 0.008684 Acc: 0.933100                                                      \n",
      "Epoch: 80 Training: Loss: 0.004033 Acc: 0.964820  Validation Loss: 0.008528 Acc: 0.933200                                                      \n",
      "Epoch: 81 Training: Loss: 0.004055 Acc: 0.964300  Validation Loss: 0.008662 Acc: 0.932500                                                      \n",
      "Epoch: 82 Training: Loss: 0.004064 Acc: 0.964700  Validation Loss: 0.008624 Acc: 0.933400                                                      \n",
      "Epoch: 83 Training: Loss: 0.004010 Acc: 0.965220  Validation Loss: 0.008674 Acc: 0.933800                                                      \n",
      "Epoch: 84 Training: Loss: 0.003939 Acc: 0.965400  Validation Loss: 0.008652 Acc: 0.933100                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 85 Training: Loss: 0.004094 Acc: 0.964400  Validation Loss: 0.008625 Acc: 0.932400                                                      \n",
      "Epoch: 86 Training: Loss: 0.004037 Acc: 0.965120  Validation Loss: 0.008655 Acc: 0.933300                                                      \n",
      "Epoch: 87 Training: Loss: 0.004006 Acc: 0.965420  Validation Loss: 0.008571 Acc: 0.933100                                                      \n",
      "Epoch: 88 Training: Loss: 0.003986 Acc: 0.965040  Validation Loss: 0.008559 Acc: 0.933300                                                      \n",
      "Epoch: 89 Training: Loss: 0.003982 Acc: 0.964780  Validation Loss: 0.008665 Acc: 0.932100                                                      \n",
      "Epoch: 90 Training: Loss: 0.003976 Acc: 0.965780  Validation Loss: 0.008626 Acc: 0.934100                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 91 Training: Loss: 0.004008 Acc: 0.965240  Validation Loss: 0.008621 Acc: 0.933600                                                      \n",
      "Epoch: 92 Training: Loss: 0.004090 Acc: 0.964200  Validation Loss: 0.008628 Acc: 0.932800                                                      \n",
      "Epoch: 93 Training: Loss: 0.003988 Acc: 0.965520  Validation Loss: 0.008561 Acc: 0.933900                                                      \n",
      "Epoch: 94 Training: Loss: 0.004004 Acc: 0.964820  Validation Loss: 0.008559 Acc: 0.933900                                                      \n",
      "Epoch: 95 Training: Loss: 0.004052 Acc: 0.964100  Validation Loss: 0.008634 Acc: 0.933100                                                      \n",
      "Epoch: 96 Training: Loss: 0.004024 Acc: 0.964680  Validation Loss: 0.008595 Acc: 0.934900                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 97 Training: Loss: 0.003893 Acc: 0.965620  Validation Loss: 0.008604 Acc: 0.933200                                                      \n",
      "Epoch: 98 Training: Loss: 0.003993 Acc: 0.965480  Validation Loss: 0.008683 Acc: 0.933000                                                      \n",
      "Epoch: 99 Training: Loss: 0.003932 Acc: 0.965940  Validation Loss: 0.008623 Acc: 0.932500                                                      \n",
      "Epoch: 100 Training: Loss: 0.003977 Acc: 0.965700  Validation Loss: 0.008578 Acc: 0.934100                                                      \n",
      "Epoch: 101 Training: Loss: 0.003968 Acc: 0.965580  Validation Loss: 0.008589 Acc: 0.933200                                                      \n",
      "Epoch: 102 Training: Loss: 0.004012 Acc: 0.965640  Validation Loss: 0.008633 Acc: 0.934100                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 103 Training: Loss: 0.003929 Acc: 0.965920  Validation Loss: 0.008593 Acc: 0.933500                                                      \n",
      "Epoch: 104 Training: Loss: 0.004095 Acc: 0.963600  Validation Loss: 0.008619 Acc: 0.932300                                                      \n",
      "Epoch: 105 Training: Loss: 0.004040 Acc: 0.964700  Validation Loss: 0.008549 Acc: 0.934200                                                      \n",
      "Epoch: 106 Training: Loss: 0.003989 Acc: 0.964080  Validation Loss: 0.008551 Acc: 0.933700                                                      \n",
      "Epoch: 107 Training: Loss: 0.003915 Acc: 0.965920  Validation Loss: 0.008742 Acc: 0.932900                                                      \n",
      "Epoch: 108 Training: Loss: 0.004061 Acc: 0.964740  Validation Loss: 0.008550 Acc: 0.933700                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 109 Training: Loss: 0.004014 Acc: 0.964660  Validation Loss: 0.008649 Acc: 0.933300                                                      \n",
      "Epoch: 110 Training: Loss: 0.003945 Acc: 0.965860  Validation Loss: 0.008713 Acc: 0.933000                                                      \n",
      "Epoch: 111 Training: Loss: 0.004005 Acc: 0.964840  Validation Loss: 0.008546 Acc: 0.933600                                                      \n",
      "Epoch: 112 Training: Loss: 0.003989 Acc: 0.964880  Validation Loss: 0.008625 Acc: 0.932700                                                      \n",
      "Epoch: 113 Training: Loss: 0.004091 Acc: 0.964420  Validation Loss: 0.008716 Acc: 0.933400                                                      \n",
      "Epoch: 114 Training: Loss: 0.004079 Acc: 0.964000  Validation Loss: 0.008671 Acc: 0.933400                                                      \n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 115 Training: Loss: 0.004016 Acc: 0.964220  Validation Loss: 0.008649 Acc: 0.933100                                                      \n",
      "Epoch: 116 Training: Loss: 0.003983 Acc: 0.964940  Validation Loss: 0.008636 Acc: 0.933200                                                      \n",
      "Epoch: 117 Training: Loss: 0.003959 Acc: 0.965680  Validation Loss: 0.008512 Acc: 0.933300                                                      \n",
      "Epoch: 118 Training: Loss: 0.003989 Acc: 0.964640  Validation Loss: 0.008654 Acc: 0.933300                                                      \n",
      "Epoch: 119 Training: Loss: 0.003986 Acc: 0.965140  Validation Loss: 0.008688 Acc: 0.932800                                                      \n",
      "Test Loss: 0.008688                                                                                                                         \n",
      "Accuracy: 0.9327999999999946\n"
     ]
    }
   ],
   "source": [
    "# self.model = torchvision.models.resnet18(weights=None)\n",
    "# self.model.conv1 = Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "# self.model.maxpool = nn.Identity()\n",
    "# self.model.fc = Linear(512, self.num_classes, bias=True)\n",
    "# self.optimizer: torch.optim.Adam = optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "# self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.1, patience=2,\n",
    "#                                                             threshold=0.0001, threshold_mode='rel', cooldown=0,\n",
    "#                                                             min_lr=0, eps=1e-08, verbose=True)\n",
    "\n",
    "modelA = ModelManager(NUM_CLASSES, load=False, dir_=NOTEBOOK_NAME, model_name='modelA')\n",
    "print(modelA.model)\n",
    "print(modelA.optimizer)\n",
    "print(modelA.scheduler)\n",
    "modelA.train(loader_train, loader_test, loader_test, EPOCHS * 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x00000241D5E72740>\n",
      "Epoch: 0 Training: Loss: 0.057940 Acc: 0.472000  Validation Loss: 0.040023 Acc: 0.640600                                                     \n",
      "Validation loss decreased (inf --> 0.040023).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 1 Training: Loss: 0.041305 Acc: 0.634620  Validation Loss: 0.032114 Acc: 0.722100                                                      \n",
      "Validation loss decreased (0.040023 --> 0.032114).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 2 Training: Loss: 0.033577 Acc: 0.705560  Validation Loss: 0.025774 Acc: 0.778500                                                      \n",
      "Validation loss decreased (0.032114 --> 0.025774).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 3 Training: Loss: 0.028714 Acc: 0.749380  Validation Loss: 0.023702 Acc: 0.793800                                                      \n",
      "Validation loss decreased (0.025774 --> 0.023702).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 4 Training: Loss: 0.025068 Acc: 0.782120  Validation Loss: 0.020808 Acc: 0.821700                                                      \n",
      "Validation loss decreased (0.023702 --> 0.020808).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 5 Training: Loss: 0.022641 Acc: 0.802640  Validation Loss: 0.019259 Acc: 0.837900                                                      \n",
      "Validation loss decreased (0.020808 --> 0.019259).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 6 Training: Loss: 0.020611 Acc: 0.822040  Validation Loss: 0.018203 Acc: 0.849300                                                      \n",
      "Validation loss decreased (0.019259 --> 0.018203).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 7 Training: Loss: 0.019120 Acc: 0.833440  Validation Loss: 0.016676 Acc: 0.861100                                                      \n",
      "Validation loss decreased (0.018203 --> 0.016676).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 8 Training: Loss: 0.017761 Acc: 0.846020  Validation Loss: 0.015638 Acc: 0.865200                                                      \n",
      "Validation loss decreased (0.016676 --> 0.015638).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 9 Training: Loss: 0.016628 Acc: 0.855060  Validation Loss: 0.014590 Acc: 0.875700                                                      \n",
      "Validation loss decreased (0.015638 --> 0.014590).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 10 Training: Loss: 0.015500 Acc: 0.864800  Validation Loss: 0.013601 Acc: 0.883600                                                      \n",
      "Validation loss decreased (0.014590 --> 0.013601).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 11 Training: Loss: 0.014464 Acc: 0.874540  Validation Loss: 0.014955 Acc: 0.875000                                                      \n",
      "Epoch: 12 Training: Loss: 0.013615 Acc: 0.879560  Validation Loss: 0.013324 Acc: 0.887400                                                      \n",
      "Validation loss decreased (0.013601 --> 0.013324).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 13 Training: Loss: 0.012999 Acc: 0.886500  Validation Loss: 0.013521 Acc: 0.886700                                                      \n",
      "Epoch: 14 Training: Loss: 0.012319 Acc: 0.891400  Validation Loss: 0.012397 Acc: 0.896500                                                      \n",
      "Validation loss decreased (0.013324 --> 0.012397).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 15 Training: Loss: 0.011580 Acc: 0.898640  Validation Loss: 0.011506 Acc: 0.902500                                                      \n",
      "Validation loss decreased (0.012397 --> 0.011506).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 16 Training: Loss: 0.010989 Acc: 0.904540  Validation Loss: 0.011397 Acc: 0.904500                                                      \n",
      "Validation loss decreased (0.011506 --> 0.011397).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 17 Training: Loss: 0.010452 Acc: 0.907980  Validation Loss: 0.011012 Acc: 0.905500                                                      \n",
      "Validation loss decreased (0.011397 --> 0.011012).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 18 Training: Loss: 0.010230 Acc: 0.910460  Validation Loss: 0.010782 Acc: 0.910600                                                      \n",
      "Validation loss decreased (0.011012 --> 0.010782).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 19 Training: Loss: 0.009597 Acc: 0.915460  Validation Loss: 0.011476 Acc: 0.902600                                                      \n",
      "Epoch: 20 Training: Loss: 0.009236 Acc: 0.918600  Validation Loss: 0.011858 Acc: 0.901200                                                      \n",
      "Epoch 00022: reducing learning rate of group 0 to 5.0000e-04.                                                                                  \n",
      "Epoch: 21 Training: Loss: 0.008608 Acc: 0.924160  Validation Loss: 0.010914 Acc: 0.916400\n",
      "Epoch: 22 Training: Loss: 0.006568 Acc: 0.943100  Validation Loss: 0.009421 Acc: 0.926100                                                      \n",
      "Validation loss decreased (0.010782 --> 0.009421).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 23 Training: Loss: 0.006183 Acc: 0.946620  Validation Loss: 0.009292 Acc: 0.925700                                                      \n",
      "Validation loss decreased (0.009421 --> 0.009292).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 24 Training: Loss: 0.005709 Acc: 0.949420  Validation Loss: 0.009050 Acc: 0.929400                                                      \n",
      "Validation loss decreased (0.009292 --> 0.009050).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 25 Training: Loss: 0.005459 Acc: 0.951720  Validation Loss: 0.009628 Acc: 0.926100                                                      \n",
      "Epoch: 26 Training: Loss: 0.005192 Acc: 0.952920  Validation Loss: 0.010217 Acc: 0.924300                                                      \n",
      "Epoch 00028: reducing learning rate of group 0 to 2.5000e-04.                                                                                  \n",
      "Epoch: 27 Training: Loss: 0.004936 Acc: 0.956360  Validation Loss: 0.009751 Acc: 0.927600\n",
      "Epoch: 28 Training: Loss: 0.004041 Acc: 0.963560  Validation Loss: 0.009050 Acc: 0.930200                                                      \n",
      "Validation loss decreased (0.009050 --> 0.009050).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 29 Training: Loss: 0.003683 Acc: 0.967300  Validation Loss: 0.009469 Acc: 0.931800                                                      \n",
      "Epoch 00031: reducing learning rate of group 0 to 1.2500e-04.                                                                                  \n",
      "Epoch: 30 Training: Loss: 0.003457 Acc: 0.968540  Validation Loss: 0.009103 Acc: 0.932300\n",
      "Epoch: 31 Training: Loss: 0.003199 Acc: 0.972000  Validation Loss: 0.009101 Acc: 0.935500                                                      \n",
      "Epoch: 32 Training: Loss: 0.002980 Acc: 0.974000  Validation Loss: 0.009168 Acc: 0.933200                                                      \n",
      "Epoch 00034: reducing learning rate of group 0 to 6.2500e-05.                                                                                  \n",
      "Epoch: 33 Training: Loss: 0.002826 Acc: 0.975640  Validation Loss: 0.009148 Acc: 0.933200\n",
      "Epoch: 34 Training: Loss: 0.002588 Acc: 0.977440  Validation Loss: 0.008904 Acc: 0.937100                                                      \n",
      "Validation loss decreased (0.009050 --> 0.008904).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 35 Training: Loss: 0.002436 Acc: 0.978560  Validation Loss: 0.008956 Acc: 0.935700                                                      \n",
      "Epoch: 36 Training: Loss: 0.002458 Acc: 0.978120  Validation Loss: 0.008873 Acc: 0.938200                                                      \n",
      "Validation loss decreased (0.008904 --> 0.008873).  Saving model to models_data/resnet18_cifar10\\modelB\n",
      "Epoch: 37 Training: Loss: 0.002358 Acc: 0.979020  Validation Loss: 0.009012 Acc: 0.935500                                                      \n",
      "Epoch: 38 Training: Loss: 0.002374 Acc: 0.978900  Validation Loss: 0.009193 Acc: 0.936900                                                      \n",
      "Epoch 00040: reducing learning rate of group 0 to 3.1250e-05.                                                                                  \n",
      "Epoch: 39 Training: Loss: 0.002301 Acc: 0.979960  Validation Loss: 0.009037 Acc: 0.936400\n",
      "Epoch: 40 Training: Loss: 0.002232 Acc: 0.981020  Validation Loss: 0.009218 Acc: 0.938500                                                      \n",
      "Epoch: 41 Training: Loss: 0.002216 Acc: 0.980740  Validation Loss: 0.009150 Acc: 0.936400                                                      \n",
      "Epoch 00043: reducing learning rate of group 0 to 1.5625e-05.                                                                                  \n",
      "Epoch: 42 Training: Loss: 0.002077 Acc: 0.982180  Validation Loss: 0.009306 Acc: 0.937700\n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 43 Training: Loss: 0.002079 Acc: 0.982160  Validation Loss: 0.009180 Acc: 0.938400                                                      \n",
      "Epoch: 44 Training: Loss: 0.001981 Acc: 0.982820  Validation Loss: 0.009028 Acc: 0.938300                                                      \n",
      "Epoch 00046: reducing learning rate of group 0 to 7.8125e-06.                                                                                  \n",
      "Epoch: 45 Training: Loss: 0.002090 Acc: 0.981660  Validation Loss: 0.009258 Acc: 0.936900\n",
      "Epoch: 46 Training: Loss: 0.002110 Acc: 0.980840  Validation Loss: 0.009280 Acc: 0.938100                                                      \n",
      "Epoch: 47 Training: Loss: 0.002026 Acc: 0.982740  Validation Loss: 0.009162 Acc: 0.938000                                                      \n",
      "Epoch 00049: reducing learning rate of group 0 to 3.9063e-06.                                                                                  \n",
      "Epoch: 48 Training: Loss: 0.001985 Acc: 0.982800  Validation Loss: 0.009129 Acc: 0.938000\n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 49 Training: Loss: 0.001948 Acc: 0.983320  Validation Loss: 0.009308 Acc: 0.938400                                                      \n",
      "Epoch: 50 Training: Loss: 0.001979 Acc: 0.982780  Validation Loss: 0.009213 Acc: 0.938000                                                      \n",
      "Epoch 00052: reducing learning rate of group 0 to 1.9531e-06.                                                                                  \n",
      "Epoch: 51 Training: Loss: 0.001970 Acc: 0.982920  Validation Loss: 0.009181 Acc: 0.936500\n",
      "Epoch: 52 Training: Loss: 0.001962 Acc: 0.982660  Validation Loss: 0.009242 Acc: 0.937700                                                      \n",
      "Epoch: 53 Training: Loss: 0.001994 Acc: 0.983000  Validation Loss: 0.009237 Acc: 0.938000                                                      \n",
      "Epoch 00055: reducing learning rate of group 0 to 9.7656e-07.                                                                                  \n",
      "Epoch: 54 Training: Loss: 0.001906 Acc: 0.984100  Validation Loss: 0.009260 Acc: 0.938700\n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 55 Training: Loss: 0.001983 Acc: 0.982820  Validation Loss: 0.009269 Acc: 0.938200                                                      \n",
      "Epoch: 56 Training: Loss: 0.001967 Acc: 0.982820  Validation Loss: 0.009134 Acc: 0.937100                                                      \n",
      "Epoch 00058: reducing learning rate of group 0 to 4.8828e-07.                                                                                  \n",
      "Epoch: 57 Training: Loss: 0.001899 Acc: 0.984140  Validation Loss: 0.009346 Acc: 0.937900\n",
      "Epoch: 58 Training: Loss: 0.002001 Acc: 0.982500  Validation Loss: 0.009152 Acc: 0.937500                                                      \n",
      "Epoch: 59 Training: Loss: 0.002019 Acc: 0.982660  Validation Loss: 0.009207 Acc: 0.938100                                                      \n",
      "Test Loss: 0.009207                                                                                                                        \n",
      "Accuracy: 0.938099999999994\n"
     ]
    }
   ],
   "source": [
    "# self.model = torchvision.models.resnet18(weights=None)\n",
    "# self.model.conv1 = Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "# self.model.maxpool = nn.Identity()\n",
    "# self.model.fc = Linear(512, self.num_classes, bias=True)\n",
    "# self.optimizer: torch.optim.Adam = optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "# self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.5, patience=2,\n",
    "#                                                             threshold=0.0001, threshold_mode='rel', cooldown=0,\n",
    "#                                                             min_lr=1e-7, eps=1e-08, verbose=True)\n",
    "\n",
    "modelB = ModelManager(NUM_CLASSES, load=False, dir_=NOTEBOOK_NAME, model_name='modelB')\n",
    "print(modelB.model)\n",
    "print(modelB.optimizer)\n",
    "print(modelB.scheduler)\n",
    "modelB.train(loader_train, loader_test, loader_test, EPOCHS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001B780091570>\n",
      "Epoch: 0 Training: Loss: 0.002968 Acc: 0.459300  Validation Loss: 0.002427 Acc: 0.549300                                                   \n",
      "Validation loss decreased (inf --> 0.002427).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 1 Training: Loss: 0.002097 Acc: 0.623800  Validation Loss: 0.002166 Acc: 0.617600                                                   \n",
      "Validation loss decreased (0.002427 --> 0.002166).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 2 Training: Loss: 0.001727 Acc: 0.693900  Validation Loss: 0.001586 Acc: 0.723800                                                    \n",
      "Validation loss decreased (0.002166 --> 0.001586).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 3 Training: Loss: 0.001492 Acc: 0.738900  Validation Loss: 0.001366 Acc: 0.763800                                                    \n",
      "Validation loss decreased (0.001586 --> 0.001366).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 4 Training: Loss: 0.001341 Acc: 0.765520  Validation Loss: 0.001351 Acc: 0.767000                                                    \n",
      "Validation loss decreased (0.001366 --> 0.001351).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 5 Training: Loss: 0.001232 Acc: 0.785640  Validation Loss: 0.001121 Acc: 0.804200                                                    \n",
      "Validation loss decreased (0.001351 --> 0.001121).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 6 Training: Loss: 0.001135 Acc: 0.801640  Validation Loss: 0.001248 Acc: 0.782300                                                    \n",
      "Epoch: 7 Training: Loss: 0.001062 Acc: 0.810500  Validation Loss: 0.001116 Acc: 0.803100                                                    \n",
      "Validation loss decreased (0.001121 --> 0.001116).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 8 Training: Loss: 0.000991 Acc: 0.827500  Validation Loss: 0.001053 Acc: 0.817200                                                    \n",
      "Validation loss decreased (0.001116 --> 0.001053).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 9 Training: Loss: 0.000926 Acc: 0.839060  Validation Loss: 0.000979 Acc: 0.834200                                                    \n",
      "Validation loss decreased (0.001053 --> 0.000979).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 10 Training: Loss: 0.000910 Acc: 0.839300  Validation Loss: 0.001386 Acc: 0.781700                                                    \n",
      "Epoch: 11 Training: Loss: 0.000855 Acc: 0.850700  Validation Loss: 0.000948 Acc: 0.834600                                                    \n",
      "Validation loss decreased (0.000979 --> 0.000948).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 12 Training: Loss: 0.000836 Acc: 0.851980  Validation Loss: 0.000898 Acc: 0.841700                                                    \n",
      "Validation loss decreased (0.000948 --> 0.000898).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 13 Training: Loss: 0.000782 Acc: 0.864960  Validation Loss: 0.001090 Acc: 0.815500                                                    \n",
      "Epoch: 14 Training: Loss: 0.000768 Acc: 0.865860  Validation Loss: 0.001199 Acc: 0.803600                                                    \n",
      "Epoch 00016: reducing learning rate of group 0 to 5.0000e-04.                                                                                \n",
      "Epoch: 15 Training: Loss: 0.000731 Acc: 0.871300  Validation Loss: 0.000906 Acc: 0.846000\n",
      "Epoch: 16 Training: Loss: 0.000614 Acc: 0.892600  Validation Loss: 0.000820 Acc: 0.862100                                                    \n",
      "Validation loss decreased (0.000898 --> 0.000820).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 17 Training: Loss: 0.000572 Acc: 0.901240  Validation Loss: 0.000796 Acc: 0.870200                                                    \n",
      "Validation loss decreased (0.000820 --> 0.000796).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 18 Training: Loss: 0.000560 Acc: 0.900540  Validation Loss: 0.000746 Acc: 0.874900                                                    \n",
      "Validation loss decreased (0.000796 --> 0.000746).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 19 Training: Loss: 0.000545 Acc: 0.904640  Validation Loss: 0.000783 Acc: 0.872800                                                    \n",
      "Epoch: 20 Training: Loss: 0.000527 Acc: 0.907240  Validation Loss: 0.000791 Acc: 0.872700                                                    \n",
      "Epoch: 21 Training: Loss: 0.000515 Acc: 0.909820  Validation Loss: 0.000740 Acc: 0.878800                                                    \n",
      "Validation loss decreased (0.000746 --> 0.000740).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 22 Training: Loss: 0.000501 Acc: 0.912400  Validation Loss: 0.000820 Acc: 0.869000                                                    \n",
      "Epoch: 23 Training: Loss: 0.000493 Acc: 0.913740  Validation Loss: 0.000874 Acc: 0.868200                                                    \n",
      "Epoch 00025: reducing learning rate of group 0 to 2.5000e-04.                                                                                \n",
      "Epoch: 24 Training: Loss: 0.000483 Acc: 0.914760  Validation Loss: 0.000898 Acc: 0.856000\n",
      "Epoch: 25 Training: Loss: 0.000414 Acc: 0.926580  Validation Loss: 0.000609 Acc: 0.898100                                                    \n",
      "Validation loss decreased (0.000740 --> 0.000609).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 26 Training: Loss: 0.000393 Acc: 0.930480  Validation Loss: 0.000662 Acc: 0.890300                                                    \n",
      "Epoch: 27 Training: Loss: 0.000387 Acc: 0.931080  Validation Loss: 0.000629 Acc: 0.893000                                                    \n",
      "Epoch 00029: reducing learning rate of group 0 to 1.2500e-04.                                                                                \n",
      "Epoch: 28 Training: Loss: 0.000373 Acc: 0.935440  Validation Loss: 0.000634 Acc: 0.900500\n",
      "Epoch: 29 Training: Loss: 0.000339 Acc: 0.939960  Validation Loss: 0.000565 Acc: 0.906800                                                    \n",
      "Validation loss decreased (0.000609 --> 0.000565).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 30 Training: Loss: 0.000332 Acc: 0.941560  Validation Loss: 0.000610 Acc: 0.900700                                                    \n",
      "Epoch: 31 Training: Loss: 0.000317 Acc: 0.944500  Validation Loss: 0.000606 Acc: 0.902600                                                    \n",
      "Epoch 00033: reducing learning rate of group 0 to 6.2500e-05.                                                                                \n",
      "Epoch: 32 Training: Loss: 0.000311 Acc: 0.945960  Validation Loss: 0.000575 Acc: 0.907400\n",
      "Epoch: 33 Training: Loss: 0.000295 Acc: 0.948800  Validation Loss: 0.000554 Acc: 0.912300                                                    \n",
      "Validation loss decreased (0.000565 --> 0.000554).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 34 Training: Loss: 0.000286 Acc: 0.950420  Validation Loss: 0.000541 Acc: 0.911100                                                    \n",
      "Validation loss decreased (0.000554 --> 0.000541).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 35 Training: Loss: 0.000282 Acc: 0.950660  Validation Loss: 0.000564 Acc: 0.906800                                                    \n",
      "Epoch: 36 Training: Loss: 0.000282 Acc: 0.951360  Validation Loss: 0.000553 Acc: 0.911700                                                    \n",
      "Epoch 00038: reducing learning rate of group 0 to 3.1250e-05.                                                                                \n",
      "Epoch: 37 Training: Loss: 0.000273 Acc: 0.952300  Validation Loss: 0.000555 Acc: 0.913000\n",
      "Epoch: 38 Training: Loss: 0.000267 Acc: 0.952760  Validation Loss: 0.000528 Acc: 0.912500                                                    \n",
      "Validation loss decreased (0.000541 --> 0.000528).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 39 Training: Loss: 0.000263 Acc: 0.953980  Validation Loss: 0.000548 Acc: 0.911700                                                    \n",
      "Epoch: 40 Training: Loss: 0.000260 Acc: 0.955480  Validation Loss: 0.000529 Acc: 0.914900                                                    \n",
      "Epoch 00042: reducing learning rate of group 0 to 1.5625e-05.                                                                                \n",
      "Epoch: 41 Training: Loss: 0.000262 Acc: 0.953100  Validation Loss: 0.000538 Acc: 0.916100\n",
      "Epoch: 42 Training: Loss: 0.000258 Acc: 0.955400  Validation Loss: 0.000529 Acc: 0.914700                                                    \n",
      "Epoch: 43 Training: Loss: 0.000252 Acc: 0.956300  Validation Loss: 0.000534 Acc: 0.915700                                                    \n",
      "Epoch 00045: reducing learning rate of group 0 to 7.8125e-06.                                                                                \n",
      "Epoch: 44 Training: Loss: 0.000254 Acc: 0.955340  Validation Loss: 0.000531 Acc: 0.914200\n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 45 Training: Loss: 0.000254 Acc: 0.956660  Validation Loss: 0.000529 Acc: 0.913600                                                    \n",
      "Epoch: 46 Training: Loss: 0.000247 Acc: 0.956140  Validation Loss: 0.000527 Acc: 0.915000                                                    \n",
      "Validation loss decreased (0.000528 --> 0.000527).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch: 47 Training: Loss: 0.000249 Acc: 0.956100  Validation Loss: 0.000528 Acc: 0.914800                                                    \n",
      "Epoch: 48 Training: Loss: 0.000252 Acc: 0.956800  Validation Loss: 0.000529 Acc: 0.916200                                                    \n",
      "Epoch 00050: reducing learning rate of group 0 to 3.9063e-06.                                                                                \n",
      "Epoch: 49 Training: Loss: 0.000249 Acc: 0.956700  Validation Loss: 0.000530 Acc: 0.915900\n",
      "Epoch: 50 Training: Loss: 0.000251 Acc: 0.956820  Validation Loss: 0.000527 Acc: 0.915800                                                    \n",
      "Epoch: 51 Training: Loss: 0.000243 Acc: 0.957840  Validation Loss: 0.000527 Acc: 0.915900                                                    \n",
      "Epoch 00053: reducing learning rate of group 0 to 1.9531e-06.                                                                                \n",
      "Epoch: 52 Training: Loss: 0.000242 Acc: 0.957580  Validation Loss: 0.000527 Acc: 0.915800\n",
      "Load model: did_not_improve_counter=5\n",
      "Epoch: 53 Training: Loss: 0.000240 Acc: 0.958420  Validation Loss: 0.000528 Acc: 0.915700                                                    \n",
      "Epoch: 54 Training: Loss: 0.000244 Acc: 0.957280  Validation Loss: 0.000527 Acc: 0.915200                                                    \n",
      "Epoch 00056: reducing learning rate of group 0 to 9.7656e-07.                                                                                \n",
      "Epoch: 55 Training: Loss: 0.000245 Acc: 0.957620  Validation Loss: 0.000528 Acc: 0.915900\n",
      "Epoch: 56 Training: Loss: 0.000251 Acc: 0.956000  Validation Loss: 0.000528 Acc: 0.915700                                                    \n",
      "Epoch: 57 Training: Loss: 0.000244 Acc: 0.958080  Validation Loss: 0.000527 Acc: 0.915900                                                    \n",
      "Validation loss decreased (0.000527 --> 0.000527).  Saving model to models_data/resnet18_cifar10\\modelC\n",
      "Epoch 00059: reducing learning rate of group 0 to 4.8828e-07.                                                                                \n",
      "Epoch: 58 Training: Loss: 0.000243 Acc: 0.957520  Validation Loss: 0.000528 Acc: 0.915500\n",
      "Epoch: 59 Training: Loss: 0.000245 Acc: 0.957080  Validation Loss: 0.000527 Acc: 0.915300                                                    \n",
      "Test Loss: 0.000527                                                                                                                      \n",
      "Accuracy: 0.9153000000000001\n"
     ]
    }
   ],
   "source": [
    "# self.model = torchvision.models.resnet18(weights=None)\n",
    "# self.model.conv1 = Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "# self.model.maxpool = nn.Identity()\n",
    "# self.model.fc = Linear(512, self.num_classes, bias=True)\n",
    "# self.optimizer: torch.optim.Adam = optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "# self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.5, patience=2,\n",
    "#                                                             threshold=0.0001, threshold_mode='rel', cooldown=0,\n",
    "#                                                             min_lr=1e-7, eps=1e-08, verbose=True)\n",
    "# batch = 500\n",
    "modelC = ModelManager(NUM_CLASSES, load=False, dir_=NOTEBOOK_NAME, model_name='modelC')\n",
    "print(modelC.model)\n",
    "print(modelC.optimizer)\n",
    "print(modelC.scheduler)\n",
    "modelC.train(loader_train, loader_test, loader_test, EPOCHS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
