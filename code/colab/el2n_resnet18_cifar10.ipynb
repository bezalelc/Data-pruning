{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhznvyEYT_T0",
    "outputId": "e59eee77-77e4-4bd0-e259-d1563bdc5c2d"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# %cd /content/drive/MyDrive/proj/models_data\n",
    "# %ls "
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3oaGdzBzU2sh",
    "outputId": "357017d9-54b9-4f7e-ce98-6a5485651f63"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "U-WQDhUFWXuA"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nn, optim, tensor\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim, tensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# general params"
   ],
   "metadata": {
    "id": "wMNaGbLKkQZC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "PATH_DATASET = './datasets'\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 20\n",
    "NUM_TRAIN = 1000\n",
    "NUM_VALID = 100\n",
    "NUM_TEST = 100\n",
    "EPOCHS = 4\n",
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "ENSEMBLE_SIZE = 10\n",
    "PATH_MODELS_SAVE = r'/content/drive/MyDrive/proj/models_data'"
   ],
   "metadata": {
    "id": "Wiu0RyrWkP3y"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDkoqhLzFWDZ"
   },
   "source": [
    "##Usefull func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhGQqt3VDoUN"
   },
   "outputs": [],
   "source": [
    "def get_cifar10():\n",
    "    \"\"\"\n",
    "    get cifar10 train set and test set\n",
    "\n",
    "    Returns:\n",
    "        cifar10 train set and test set\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.49139968, 0.48215841, 0.44653091), (0.24703223, 0.24348513, 0.26158784))\n",
    "    ])\n",
    "\n",
    "    # train mean = [0.49139968, 0.48215841, 0.44653091]\n",
    "    # train std  = [0.24703223, 0.24348513, 0.26158784]\n",
    "\n",
    "    dataset_train = torchvision.datasets.CIFAR10(PATH_DATASET, train=True, transform=transform, download=True)\n",
    "    dataset_test = torchvision.datasets.CIFAR10(PATH_DATASET, train=False, transform=transform, download=True)\n",
    "    return dataset_train, dataset_test\n",
    "\n",
    "def get_loader(dataset, idx, shuffle=True):\n",
    "    subset = torch.utils.data.Subset(dataset, idx)\n",
    "    return torch.utils.data.DataLoader(subset, batch_size=BATCH_SIZE, shuffle=shuffle)\n",
    "\n",
    "def get_model():\n",
    "    model = models.resnet18(weights=None)  # ,pretrained=False\n",
    "    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "    # model.load_state_dict(torch.load('ResNet18.pt'))\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "    return model, criterion, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbjdcLPiGahQ"
   },
   "source": [
    "##el2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "an8EN7XrGZot"
   },
   "outputs": [],
   "source": [
    "def get_el2n_scores(y, ensemble_pred):\n",
    "    \"\"\"\n",
    "    calculate mean on the L2 over ensemble of algorithms\n",
    "\n",
    "    :param y: labels, shape: (data len)\n",
    "    :param ensemble_pred: scores for every data example, shape: (ensemble size, data len, labels len)\n",
    "\n",
    "    :return: el2n_scores: vector of scores how the example hard to learn for every data\n",
    "             shape: (data len)\n",
    "    \"\"\"\n",
    "    y_one_hot = torch.nn.functional.one_hot(y, num_classes=ensemble_pred.shape[-1])\n",
    "    return torch.mean(torch.linalg.norm(y_one_hot - ensemble_pred, ord=2, dim=2), dim=0)\n",
    "\n",
    "\n",
    "def get_prune_idx(y, ensemble_pred, prune_size: float, keep_hardest: bool = True):\n",
    "    return get_el2n_scores(y, ensemble_pred).argsort(descending=keep_hardest)[:int(prune_size * y.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RT7QmXs6FelM"
   },
   "source": [
    "##Global definations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vm_m3yl2EYf-",
    "outputId": "51b3eaaa-77e0-4917-e132-294e039b0657"
   },
   "outputs": [],
   "source": [
    "# check if CUDA is available\n",
    "TRAIN_ON_GPU = torch.cuda.is_available()\n",
    "DEVICE = 'cuda' if TRAIN_ON_GPU else 'cpu'\n",
    "\n",
    "if not TRAIN_ON_GPU:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "\n",
    "# torch.manual_seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_A_MlqwGMZ6"
   },
   "source": [
    "##train model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDqZwfngEf5T"
   },
   "outputs": [],
   "source": [
    "class Mode(Enum):\n",
    "    TRAIN = 0\n",
    "    VALIDATE = 1\n",
    "    TEST = 2\n",
    "\n",
    "\n",
    "def train(model, train_loader, valid_loader, test_loader, criterion, optimizer, epochs: int, save_path='',\n",
    "          verbose: bool = True):\n",
    "    loss_train, loss_valid, loss_valid_min, acc_train, acc_valid = [], [], np.Inf, [], []\n",
    "    scores_train, scores_valid, scores_test = None, None, None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        scores_train, loss, acc = run_epoch(model, criterion, optimizer, train_loader, Mode.TRAIN)\n",
    "        loss_train.append(loss), acc_train.append(acc)\n",
    "        scores_valid, loss, acc_test = run_epoch(model, criterion, optimizer, valid_loader, Mode.VALIDATE)\n",
    "        loss_valid.append(loss), acc_valid.append(acc)\n",
    "\n",
    "        # print training/validation statistics\n",
    "        if verbose:\n",
    "            print(f'Epoch: {epoch} Training: Loss: {loss_train[-1]:.6f} Acc: {acc_train[-1]:.6f}  '\n",
    "                  f'Validation Loss: {loss_valid[-1]:.6f} Acc: {acc_valid[-1]:.6f}')\n",
    "\n",
    "        # save model if validation loss has decreased\n",
    "        if save_path and loss_valid[-1] <= loss_valid_min:\n",
    "            if verbose:\n",
    "                print(f'Validation loss decreased ({loss_valid_min:.6f} --> {loss_valid[-1]:.6f}).  '\n",
    "                      f'Saving model to {save_path}')\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            loss_valid_min = loss_valid[-1]\n",
    "\n",
    "    scores_test, loss_test, acc_test = run_epoch(model, criterion, optimizer, test_loader, Mode.TEST)\n",
    "    if verbose:\n",
    "        print(f'Test Loss: {loss_test:.6f}')\n",
    "        print(f'Accuracy: {acc_test}')\n",
    "\n",
    "    return (scores_train, loss_train, acc_train), (scores_valid, loss_valid, acc_valid), \\\n",
    "           (scores_test, loss_test, acc_test)\n",
    "\n",
    "\n",
    "\n",
    "def run_epoch(model, criterion, optimizer, loader, mode: Mode = Mode.TRAIN):\n",
    "    model.train() if mode == Mode.TRAIN else model.eval()\n",
    "\n",
    "    loss, loss_min, acc = .0, np.Inf, .0\n",
    "    len_dataset = len(loader.dataset)\n",
    "    scores = torch.empty((len(loader.dataset), NUM_CLASSES))\n",
    "\n",
    "    for batch_idx, (X, y) in enumerate(loader):\n",
    "        if TRAIN_ON_GPU:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        if mode == Mode.TRAIN:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        p = model(X)\n",
    "        loss_batch = criterion(p, y)\n",
    "        loss += loss_batch.item()\n",
    "\n",
    "        if mode == Mode.TRAIN:\n",
    "            loss_batch.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            scores[batch_idx * BATCH_SIZE:(batch_idx + 1) * BATCH_SIZE] = p.clone().detach()\n",
    "\n",
    "        _, pred = torch.max(p, 1)\n",
    "        acc += torch.sum(pred.eq(y))\n",
    "\n",
    "    return scores, loss / len_dataset, acc / len_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "57b06e8ee98f4200989bbc9bb3e6f460",
      "9f025d1a1f3043fdad2a2b4a8d42b2c0",
      "700aa402adb5448fb7cfd0098ff7cd6b",
      "508c616169e149b093fac3d833341c96",
      "57712e5f1dd94382892455d111f5a058",
      "217838e2a7814e679325208b5f242544",
      "bc06c7b94aa14dca8736b84e61aa3fa0",
      "ed9ebf97efa34242b4d106d4c44653ba",
      "84ca1fcb0eb34ea68d8cd308759831ee",
      "601a11007fd043bebadef264a06e8a33",
      "dc9e38bc7fd34e1a9f5445bee953f4b5"
     ]
    },
    "id": "VD_ZtaoWDmbR",
    "outputId": "f54ec379-daed-4652-edfe-be67a5c2f3fe"
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "data_train, data_test = get_cifar10()\n",
    "\n",
    "loader_train = get_loader(data_train, np.arange(NUM_TRAIN))\n",
    "loader_valid = get_loader(data_train, np.arange(NUM_TRAIN, NUM_VALID + NUM_TRAIN))\n",
    "loader_test = get_loader(data_test, np.arange(NUM_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TpOHWz3YF51o",
    "outputId": "84e83c49-f994-4b9d-e489-49d69cff740b"
   },
   "outputs": [],
   "source": [
    "ensemble = [get_model() for _ in range(ENSEMBLE_SIZE)]\n",
    "prune_size = .5\n",
    "ensemble_softmax = torch.empty((len(ensemble), NUM_TRAIN, NUM_CLASSES), device=DEVICE)\n",
    "ensemble_pred = torch.empty((NUM_TRAIN, len(ensemble)), dtype=torch.bool, device=DEVICE)\n",
    "ensemble_pred_sum = torch.empty((NUM_TRAIN,), dtype=torch.int8, device=DEVICE)\n",
    "idx = np.arange(NUM_TRAIN)\n",
    "# create loader with no shuffling\n",
    "loader_prune = get_loader(data_train, idx, shuffle=False)\n",
    "Y_train = tensor(data_train.targets, device=DEVICE)[idx]\n",
    "\n",
    "for i, (model, criterion, optimizer) in enumerate(ensemble):\n",
    "    print(f'------------   model {i}   -------------------')\n",
    "    path = os.path.join(PATH_MODELS_SAVE, f'resnet18_{i}')\n",
    "    (scores_train, loss_train, acc_train), (scores_valid, loss_valid, acc_valid), (\n",
    "        scores_test, loss_test, acc_test) = \\\n",
    "        train(model, loader_train, loader_valid, loader_test, criterion, optimizer, 10, verbose=True, save_path=path)\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (X, y) in enumerate(loader_prune):\n",
    "        if TRAIN_ON_GPU:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        pred = model(X)\n",
    "        idx = np.arange(batch_idx * BATCH_SIZE, (batch_idx + 1) * BATCH_SIZE)\n",
    "        ensemble_softmax[i, idx] = F.softmax(pred, dim=1)\n",
    "        ensemble_pred[idx, i] = (torch.max(pred, 1)[1].type(torch.int8) == y)\n",
    "\n",
    "ensemble_pred_sum = torch.sum(ensemble_pred, dim=1)\n",
    "el2n_scores = get_el2n_scores(Y_train, ensemble_softmax).detach().cpu().numpy()\n",
    "\n",
    "# save data\n",
    "torch.save(ensemble_pred_sum, os.path.join(PATH_MODELS_SAVE, 'ensemble_pred_sum.pt'))\n",
    "torch.save(ensemble_pred, os.path.join(PATH_MODELS_SAVE, 'ensemble_pred.pt'))\n",
    "torch.save(ensemble_softmax, os.path.join(PATH_MODELS_SAVE, 'ensemble_softmax.pt'))\n",
    "torch.save(el2n_scores, os.path.join(PATH_MODELS_SAVE, 'el2n_scores.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# "
   ],
   "metadata": {
    "id": "Qwpx3578I6hn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# for each model: count how mach prediction was true\n",
    "torch.sum(ensemble_pred, dim=0)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "id": "m3xtaMRd1Msc",
    "outputId": "84849519-7cac-4d07-c198-fe7efa48460e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.hist(ensemble_pred_sum.cpu(), bins=len(ensemble), facecolor='g', alpha=0.6)\n",
    "plt.xlabel('models')\n",
    "plt.ylabel('examples per bin')\n",
    "plt.title('Number of models success hist')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "Ae5zATJbAkRw",
    "outputId": "8b289f09-9719-4f98-9f29-fa0c6b421ce9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.hist(el2n_scores, bins=len(data_train.classes), facecolor='g', alpha=0.6)\n",
    "plt.xlabel('models')\n",
    "plt.ylabel('examples per bin')\n",
    "plt.title('EL2N hist')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "IXq-sWLsjDcX",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "outputId": "f761da87-a662-4b22-bc28-817168a81fb7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# [easy,...,hard]\n",
    "data_train_raw = torchvision.datasets.CIFAR10(PATH_DATASET, train=True)\n",
    "el2n_scores_idx = np.argsort(el2n_scores)\n",
    "plt.style.use('default')\n",
    "fig, axes = plt.subplots(3, 4, figsize=(15, 15))\n",
    "fig.suptitle('Easiest examples')\n",
    "plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9)\n",
    "for ax, i in zip(axes.reshape(-1), el2n_scores_idx[:12]):\n",
    "    ax.imshow(data_train_raw[i][0])\n",
    "    ax.set_title(f'EL2N {el2n_scores[i]:.3f}, Class: {data_train_raw.classes[data_train_raw[i][1]]}')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "QZcItGRujDmn",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "ddf7d2a7-a1b2-4548-962c-4a0c3e78d6b2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hardest examples"
   ],
   "metadata": {
    "id": "bxkNybdgjfvc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(15, 15))\n",
    "fig.suptitle('Hardest examples')\n",
    "plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9)\n",
    "for ax, i in zip(axes.reshape(-1), el2n_scores_idx[-12:][::-1]):\n",
    "    ax.imshow(data_train_raw[i][0])\n",
    "    ax.set_title(f'EL2N {el2n_scores[i]:.3f}, Class: {data_train_raw.classes[data_train_raw[i][1]]}')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "FWOeqkl4jf9J",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "80398df6-1541-42bb-ad71-b2f7610baadf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "M = ensemble_pred.clone().detach().cpu()"
   ],
   "metadata": {
    "id": "nDWrLVcBjvOt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "idx_to_keep = get_prune_idx(Y_train, ensemble_softmax, prune_size)\n",
    "\n",
    "loader_train = get_loader(data_train, idx_to_keep, True)\n",
    "model_prune, criterion_prune, optimizer_prune = get_model()\n",
    "model_simple, criterion_simple, optimizer_simple = get_model()"
   ],
   "metadata": {
    "id": "Wpn-nPw5jzv3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qKeToiTk-5o"
   },
   "outputs": [],
   "source": [
    "# train model with prune\n",
    "(scores_train_p, loss_train_p, acc_train_p), (\n",
    "    scores_valid_p, loss_valid_p, acc_valid_p), (\n",
    "    scores_test_p, loss_test_p, acc_test_p) = \\\n",
    "    train(model_prune, loader_prune, loader_valid, loader_test, criterion_prune, optimizer_prune, EPOCHS,\n",
    "          verbose=True, save_path=os.path.join(PATH_MODELS_SAVE, 'resnet18_prune'))\n",
    "# torch.save(model_simple.state_dict(), './model_simple.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XCH2QNHlCYq"
   },
   "outputs": [],
   "source": [
    "# train model without prune\n",
    "(scores_train, loss_train, acc_train), (scores_valid, loss_valid, acc_valid), (\n",
    "    scores_test, loss_test, acc_test) = \\\n",
    "    train(model_simple, loader_train, loader_valid, loader_test, criterion_simple, optimizer_simple, EPOCHS,\n",
    "          verbose=True, save_path=os.path.join(PATH_MODELS_SAVE, 'resnet18_no_prune'))\n",
    "# torch.save(model_prune.state_dict(), './model_prune.pt')\n",
    "# load: model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "fig, (ax_train_loss, ax_valid_loss) = plt.subplots(1, 2)\n",
    "ax_train_loss.plot(np.arange(EPOCHS), loss_train_p, label='prune')\n",
    "ax_train_loss.plot(np.arange(EPOCHS), loss_train, label='simple')\n",
    "ax_train_loss.set_title('train loss')\n",
    "ax_valid_loss.plot(np.arange(EPOCHS), loss_valid_p, label='prune')\n",
    "ax_valid_loss.plot(np.arange(EPOCHS), loss_valid, label='simple')\n",
    "ax_valid_loss.set_title('valid loss')\n",
    "\n",
    "for ax in (ax_train_loss, ax_valid_loss):\n",
    "    ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('loss')\n",
    "ax.grid(True)\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "zqwozB4LkLbo"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "57b06e8ee98f4200989bbc9bb3e6f460": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f025d1a1f3043fdad2a2b4a8d42b2c0",
       "IPY_MODEL_700aa402adb5448fb7cfd0098ff7cd6b",
       "IPY_MODEL_508c616169e149b093fac3d833341c96"
      ],
      "layout": "IPY_MODEL_57712e5f1dd94382892455d111f5a058"
     }
    },
    "9f025d1a1f3043fdad2a2b4a8d42b2c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_217838e2a7814e679325208b5f242544",
      "placeholder": "​",
      "style": "IPY_MODEL_bc06c7b94aa14dca8736b84e61aa3fa0",
      "value": "100%"
     }
    },
    "700aa402adb5448fb7cfd0098ff7cd6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed9ebf97efa34242b4d106d4c44653ba",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_84ca1fcb0eb34ea68d8cd308759831ee",
      "value": 170498071
     }
    },
    "508c616169e149b093fac3d833341c96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_601a11007fd043bebadef264a06e8a33",
      "placeholder": "​",
      "style": "IPY_MODEL_dc9e38bc7fd34e1a9f5445bee953f4b5",
      "value": " 170498071/170498071 [00:14&lt;00:00, 13766159.29it/s]"
     }
    },
    "57712e5f1dd94382892455d111f5a058": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "217838e2a7814e679325208b5f242544": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc06c7b94aa14dca8736b84e61aa3fa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ed9ebf97efa34242b4d106d4c44653ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84ca1fcb0eb34ea68d8cd308759831ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "601a11007fd043bebadef264a06e8a33": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc9e38bc7fd34e1a9f5445bee953f4b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}