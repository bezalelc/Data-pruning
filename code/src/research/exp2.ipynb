{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on  GPU...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from torch import tensor, nn, Tensor\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(r'../../'))\n",
    "\n",
    "from src.utils.common import get_model_resnet18_cifar10, get_loader, create_saved_data_dir, get_device, save, load\n",
    "from src.utils.dataset import get_cifar, GPUDataset\n",
    "from src.utils.plot import plot_loss_acc,plot_img_and_top\n",
    "from src.utils.train import ModelManager, Mode\n",
    "from src.config import PATH_SAVE_MODELS, PATH_DATASETS\n",
    "\n",
    "\n",
    "# globals\n",
    "NUM_CLASSES = 100\n",
    "BATCH_SIZE = 25\n",
    "NUM_TRAIN = 50000\n",
    "NUM_TEST = 10000\n",
    "# PRUNE_EPOCHS = 2\n",
    "EPOCHS = 100\n",
    "\n",
    "DEVICE = get_device()\n",
    "\n",
    "train_idx = np.arange(NUM_TRAIN, dtype=int)\n",
    "test_idx = np.arange(NUM_TEST, dtype=int)\n",
    "dataset_train, dataset_test, dataset_train_ordered, dataset_train_raw = get_cifar(PATH_DATASETS)\n",
    "loader_train = get_loader(dataset_train, train_idx, BATCH_SIZE)\n",
    "loader_test = get_loader(dataset_test, test_idx, BATCH_SIZE, False)\n",
    "loader_train_ordered = get_loader(dataset_train_ordered, train_idx, BATCH_SIZE, False)\n",
    "\n",
    "Y_train = Tensor(dataset_train.targets)[train_idx].type(torch.int64)\n",
    "Y_test = Tensor(dataset_test.targets)[test_idx].type(torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# no prun"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=200, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch: 0 Training: Loss: 0.154115 Acc: 0.106820  Validation Loss: 0.136601 Acc: 0.172800                                                    \n",
      "Validation loss decreased (inf --> 0.136601).  Saving model to models_data/prune_25p\\no_prune\n",
      "Epoch: 1 Training: Loss: 0.132382 Acc: 0.194180  Validation Loss: 0.121448 Acc: 0.239000                                                    \n",
      "Validation loss decreased (0.136601 --> 0.121448).  Saving model to models_data/prune_25p\\no_prune\n",
      "Epoch 2 Train: ███████████████████████▊                                      793/2000 [00:43<01:05, 18.39 batch/s, acc=9.63%, loss=0.048] ]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m regular_model \u001B[38;5;241m=\u001B[39m ModelManager(NUM_CLASSES, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mno_prune\u001B[39m\u001B[38;5;124m'\u001B[39m, dir_\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprune_25p\u001B[39m\u001B[38;5;124m'\u001B[39m, load\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(regular_model\u001B[38;5;241m.\u001B[39mmodel)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mregular_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloader_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloader_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloader_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Data-pruning\\code\\src\\utils\\train.py:339\u001B[0m, in \u001B[0;36mModelManager.train\u001B[1;34m(self, train_loader, valid_loader, test_loader, epochs, verbose)\u001B[0m\n\u001B[0;32m    337\u001B[0m \u001B[38;5;66;03m# with torch.autograd.profiler.profile(enabled=False), torch.autograd.detect_anomaly(check_nan=False):\u001B[39;00m\n\u001B[0;32m    338\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepochs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepochs \u001B[38;5;241m+\u001B[39m epochs):\n\u001B[1;32m--> 339\u001B[0m     _, _, loss, acc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTRAIN\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    340\u001B[0m     loss_train\u001B[38;5;241m.\u001B[39mappend(loss), acc_train\u001B[38;5;241m.\u001B[39mappend(acc)\n\u001B[0;32m    341\u001B[0m     _, _, loss, acc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_epoch(valid_loader, Mode\u001B[38;5;241m.\u001B[39mVALIDATE)\n",
      "File \u001B[1;32m~\\Documents\\Data-pruning\\code\\src\\utils\\train.py:313\u001B[0m, in \u001B[0;36mModelManager.run_epoch\u001B[1;34m(self, loader, mode)\u001B[0m\n\u001B[0;32m    310\u001B[0m     scores[batch_idx \u001B[38;5;241m*\u001B[39m loader\u001B[38;5;241m.\u001B[39mbatch_size:(batch_idx \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m loader\u001B[38;5;241m.\u001B[39mbatch_size] \u001B[38;5;241m=\u001B[39m p\u001B[38;5;241m.\u001B[39mclone()\u001B[38;5;241m.\u001B[39mdetach()\n\u001B[0;32m    312\u001B[0m _, pred_ \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(p, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 313\u001B[0m acc \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpred_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meq\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m len_dataset\n\u001B[0;32m    314\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m Mode\u001B[38;5;241m.\u001B[39mTEST:\n\u001B[0;32m    315\u001B[0m     pred[batch_idx \u001B[38;5;241m*\u001B[39m loader\u001B[38;5;241m.\u001B[39mbatch_size:(batch_idx \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m loader\u001B[38;5;241m.\u001B[39mbatch_size] \u001B[38;5;241m=\u001B[39m pred_\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "regular_model = ModelManager(NUM_CLASSES, 'no_prune', dir_='prune_25p', load=False)\n",
    "print(regular_model.model)\n",
    "regular_model.train(loader_train, loader_test, loader_test, EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get prune scores\n",
    "data = torch.load(os.path.join(PATH_SAVE_MODELS, 'el2n', 'general.pt'))\n",
    "\n",
    "ensemble_softmax = data['ensemble_softmax']\n",
    "ensemble_pred = data['ensemble_pred']\n",
    "ensemble_pred_sum = data['ensemble_pred_sum']\n",
    "ensemble_std = data['ensemble_std']\n",
    "el2n_scores = data['el2n_scores']\n",
    "forgetting_model = ModelManager(NUM_CLASSES, 'forgetting', load=True)\n",
    "change_counter = forgetting_model.data_other['change_counter']\n",
    "\n",
    "idx_sorted_el2n = el2n_scores.sort()[1].numpy()[:NUM_TRAIN]\n",
    "idx_sorted_forgetting = change_counter.sort()[1].numpy()[:NUM_TRAIN]\n",
    "idx_sorted_std = ensemble_std.sort()[1].numpy()[:NUM_TRAIN]\n",
    "idx_sorted_pred_sum = ensemble_pred_sum.sort()[1].numpy()[:NUM_TRAIN]\n",
    "idx_random_prune = np.random.choice(np.arange(NUM_TRAIN), NUM_TRAIN, replace=False)\n",
    "\n",
    "idx = {'el2n': idx_sorted_el2n, 'forget': idx_sorted_forgetting, 'std': idx_sorted_std, 'pred_sum': idx_sorted_pred_sum,\n",
    "       'random': idx_random_prune}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = [regular_model]\n",
    "\n",
    "loss, acc = [], []\n",
    "num_train = int(NUM_TRAIN * (75. / 100.))\n",
    "\n",
    "print()\n",
    "for name, idx in idx.items():\n",
    "    print(f'====     train model with 25% prune according to {name} most hard     ======')\n",
    "    loader_train = get_loader(dataset_train, idx_sorted_el2n[-num_train:], BATCH_SIZE, True)\n",
    "\n",
    "    model_manager = ModelManager(NUM_CLASSES, f'prune_25p_{name}', dir_='prune_25p', load=False)\n",
    "    model_manager.train(loader_train, loader_test, loader_test, EPOCHS)\n",
    "\n",
    "    models.append(model_manager)\n",
    "    acc.append(model_manager.data['test']['acc']), loss.append(model_manager.data['test']['loss'])\n",
    "    print()\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(17, 4))\n",
    "# axes[0].plot(EPOCHS, loss)\n",
    "# axes[0].set_xlabel('prune size')\n",
    "# axes[0].set_ylabel('Loss')\n",
    "# axes[1].plot(EPOCHS, acc)\n",
    "# axes[1].set_xlabel('prune size')\n",
    "# axes[1].set_ylabel('Acc')\n",
    "# fig.subplots_adjust(wspace=.4)\n",
    "# plt.plot()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ModelManager.save_models_log(models, 'prune_25p')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                EL2N       Std  True p sum    Forget\nEL2N        1.000000  0.335860   -0.884456  0.522132\nStd         0.335860  1.000000   -0.260599  0.243458\nTrue p sum -0.884456 -0.260599    1.000000 -0.526172\nForget      0.522132  0.243458   -0.526172  1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EL2N</th>\n      <th>Std</th>\n      <th>True p sum</th>\n      <th>Forget</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>EL2N</th>\n      <td>1.000000</td>\n      <td>0.335860</td>\n      <td>-0.884456</td>\n      <td>0.522132</td>\n    </tr>\n    <tr>\n      <th>Std</th>\n      <td>0.335860</td>\n      <td>1.000000</td>\n      <td>-0.260599</td>\n      <td>0.243458</td>\n    </tr>\n    <tr>\n      <th>True p sum</th>\n      <td>-0.884456</td>\n      <td>-0.260599</td>\n      <td>1.000000</td>\n      <td>-0.526172</td>\n    </tr>\n    <tr>\n      <th>Forget</th>\n      <td>0.522132</td>\n      <td>0.243458</td>\n      <td>-0.526172</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forgetting_model = ModelManager(NUM_CLASSES, 'forgetting', load=True)\n",
    "change_counter = forgetting_model.data_other['change_counter']\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'EL2N': el2n_scores.numpy(),\n",
    "    'Std': ensemble_std.sum(dim=1).numpy(),\n",
    "    'True p sum': ensemble_pred_sum.numpy(),  # number of models that right on each example\n",
    "    'Forget': change_counter.numpy()\n",
    "})\n",
    "data.corr()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "           EL2N       Std  True p sum  Forget\n0      0.973247  0.915261           1       3\n1      0.747732  0.918816           9       1\n2      0.713550  0.857692           9       0\n3      0.891754  0.693117           3       2\n4      0.999180  0.784892           0       5\n...         ...       ...         ...     ...\n49995  0.970681  0.671530           1       4\n49996  1.020862  1.020247           0       3\n49997  1.065145  1.150500           1       5\n49998  0.978251  0.695142           0       4\n49999  0.718129  0.749687           7       3\n\n[50000 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EL2N</th>\n      <th>Std</th>\n      <th>True p sum</th>\n      <th>Forget</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.973247</td>\n      <td>0.915261</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.747732</td>\n      <td>0.918816</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.713550</td>\n      <td>0.857692</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.891754</td>\n      <td>0.693117</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.999180</td>\n      <td>0.784892</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>0.970681</td>\n      <td>0.671530</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>1.020862</td>\n      <td>1.020247</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>1.065145</td>\n      <td>1.150500</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>0.978251</td>\n      <td>0.695142</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>0.718129</td>\n      <td>0.749687</td>\n      <td>7</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
